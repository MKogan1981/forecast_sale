{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from collections import defaultdict, Counter\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    # определение устройства на котором будут производиться рассчеты\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    # информация о данных и путях\n",
    "    pathToFile_csv = 'learning_itemData_172_week_2021-03-31 .csv',\n",
    "    vectorizer_file = \"vectorizer.json\",\n",
    "    model_state_file = \"model.pth\",\n",
    "    save_dir = \"C:\\\\Users\\\\MKoga\\\\MyProgramms\\\\BusinessAnalysis\",\n",
    "    train_proportion = 0.005,\n",
    "    val_proportion = 0.005,\n",
    "    test_proportion = 0.99,\n",
    "    # Гиперпараметры модели\n",
    "    rnn_hidden_size = 180,\n",
    "    # hidden_dim = ...\n",
    "    # Гиперпараметры обучения\n",
    "    seed = 1234,\n",
    "    num_epochs = 25,\n",
    "    learning_rate = 8e-5,\n",
    "    num_layers = 2,\n",
    "    batch_size = 32,\n",
    "    logNormToNormData = lambda x : np.log(x + np.exp(1)),\n",
    "    normToLogNormData = lambda x : np.exp(x) - np.exp(1),\n",
    "\n",
    ")\n",
    "\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерировать новые данные на базе существующих. Добавлением шума (случайные сдвиги продаж на 1 еденицу +-). Перестановка недель (и пар ближайших недель) продаж. Разыгрывание переставляемых недель с вероятностью уменьшающейся от растояния в неделях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N(μ, σ^2)  σ * np.matlib.randn() + μ\n",
    "noiseMatrix = ((0.9 * np.matlib.randn(53)))\n",
    "noiseMatrix = np.floor(np.resize(noiseMatrix, (53,)) + 0.5).astype(np.int32)\n",
    "print(noiseMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "position = np.random.randint(1, 54)\n",
    "nElements = np.random.randint(1, 4)\n",
    "shift = (1.2 * np.matlib.randn(1))\n",
    "shift = np.floor(np.resize(shift, (1,)) + 0.5).astype(np.int32)[0]\n",
    "print(position, nElements, shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class itemsDataset(Dataset):\n",
    "    def __init__(self, data_df):\n",
    "        \"\"\"\n",
    "        Аргументы:\n",
    "            data_df (pandas.DataFrame)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.data_in_df = data_df[0] \n",
    "        self.data_out_df = data_df[1]\n",
    "        \n",
    "        self.numData_Substring = len(['pseudoRemainder', 'pseudoSales'])\n",
    "        \n",
    "        self.train_in_df = self.data_in_df[self.data_in_df.split == 'train']\n",
    "        self.train_out_df = self.data_out_df[self.data_out_df.split == 'train']\n",
    "        self.train_size = int(len(self.train_out_df)) \n",
    "        #print('train in', self.train_size)\n",
    "        \n",
    "        self.val_in_df  = self.data_in_df[self.data_in_df.split == 'val']\n",
    "        self.val_out_df  = self.data_out_df[self.data_out_df.split == 'val']\n",
    "        self.validation_size = int(len(self.val_out_df))\n",
    "        #print(self.validation_size)\n",
    "        \n",
    "        self.test_in_df = self.data_in_df[self.data_in_df.split == 'test']\n",
    "        self.test_out_df = self.data_out_df[self.data_out_df.split == 'test']\n",
    "        self.test_size = int(len(self.test_out_df))\n",
    "        #print(self.test_size)\n",
    "        \n",
    "        self._lookup_dict = {'train' : (self.train_in_df, self.train_out_df, self.train_size), \n",
    "                             'val' : (self.val_in_df, self.val_out_df, self.validation_size), \n",
    "                             'test' : (self.test_in_df, self.test_out_df, self.test_size)}\n",
    "        \n",
    "        self.set_split('train')\n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset(cls, pathToFile_csv):\n",
    "        # Получаем данные и создаем обучающий (train), проверочный (val) и контрольный (test) фрагменты\n",
    "        itemData= pd.read_csv(args.pathToFile_csv, header= None, sep= '\\s+', encoding= 'cp1251')\n",
    "        # Подготовка данных preparation data\n",
    "        itemData= np.array(itemData)\n",
    "        listItem = itemData[:, 0]\n",
    "        \n",
    "        for i, item in enumerate(listItem): \n",
    "            if item == \"None\":\n",
    "                itemData = np.delete(itemData, i, 0)\n",
    "                listItem = np.delete(listItem, i, 0)\n",
    "                print(i, item)  \n",
    "                       \n",
    "                \n",
    "        # Получение информации о сбалансированности данных \n",
    "        # всего на вход 156 недели из них используем 172-52 = 120  (120 + 52 сдвиг для формирования новых данных)\n",
    "        allWeek = round((itemData.shape[1] - 1) / 3)\n",
    "        yearByWeek = 52 \n",
    "        useNumWeek = allWeek - yearByWeek \n",
    "        print('allWeek {}, useNumWeek {}'.format(allWeek, useNumWeek))\n",
    "        rem = np.zeros((itemData.shape[0], allWeek), dtype=np.float32)\n",
    "        salesData = np.zeros((itemData.shape[0], allWeek), dtype=np.float32) \n",
    "        itemAverageSales = np.zeros(itemData.shape[0], dtype=np.float32)\n",
    "        for item in range(itemData.shape[0]): \n",
    "            for i in range(allWeek):\n",
    "                rem[item, i] = (0.4 * itemData[item, 3*i + 2] + 0.6 * itemData[item, 3*i+ 3])\n",
    "                tempRem = rem[item, i] if rem[item, i] >= 1. else 1.\n",
    "                salesData[item, i] = (itemData[item, 3*i + 1] / np.log10(tempRem + 1.))\n",
    "        \n",
    "        itemAverageSales =  np.mean(salesData, axis=1) \n",
    "        print(itemAverageSales.shape)\n",
    "        bins = np.array([0.3, 0.9, 3, 8, 10000])\n",
    "        nDataInBin = np.zeros(len(bins), dtype=np.int32)\n",
    "        temp = np.zeros(len(bins), dtype=np.int32)\n",
    "        for i in range(len(bins)):\n",
    "            nDataInBin[i] = (itemAverageSales <= bins[i]).sum()\n",
    "            temp[i] = nDataInBin[i]\n",
    "        for i in range(len(bins)):\n",
    "            if i == 0:\n",
    "                print('[ средние продажи в интервале %.3f - %.3f ]  - товаров %5d' %(0, bins[i], nDataInBin[i]))\n",
    "            else:\n",
    "                nDataInBin[i] -= temp[i-1]\n",
    "                print('[ средние продажи в интервале %.3f - %.3f ]  - товаров %5d' %(bins[i-1], bins[i], nDataInBin[i]))        \n",
    "        \n",
    "        # --------------------------------------------------    \n",
    "\n",
    "        # выравниваем группы данных (разбивка по среднем продажам) увеличивая набор данных (аугментация)\n",
    "        \n",
    "        # nSliceToBin = np.array([0, 1, 1, 1, 2]) \n",
    "        # при таком выборе времянных рядов вход одних не может быть выходом других\n",
    "        nSliceToChoice = np.array([0, 1, 1, 1, 1])\n",
    "        \n",
    "        quantityData = np.sum([nSliceToChoice[i] * nDataInBin[i] for i in range(len(nSliceToChoice))])\n",
    "        print('quantity of example - %5d' %quantityData)\n",
    "                \n",
    "        inRemainderData = np.zeros((quantityData, useNumWeek), dtype=np.float32)\n",
    "        inItemSalesData = np.zeros((quantityData, useNumWeek), dtype=np.float32)\n",
    "        # выходные данные на 120 (useNumWeek) недели\n",
    "        # всего 172 (allWeek) недели из них выбираем периоды в 120 недели\n",
    "        remainderData = np.zeros((quantityData, useNumWeek), dtype=np.float32)\n",
    "        itemSalesData = np.zeros((quantityData, useNumWeek), dtype=np.float32)\n",
    "        meanSaleByNumberWeekInYear = np.zeros((quantityData, useNumWeek), dtype=np.float32)\n",
    "        print(itemData.shape, itemSalesData.shape, remainderData.shape, inItemSalesData.shape, inRemainderData.shape) \n",
    "        listItemIndex = []\n",
    "        for itemNum in range(itemData.shape[0]):\n",
    "            rateIndex = 0\n",
    "            for i in range(len(bins)):\n",
    "                if itemAverageSales[itemNum] <= bins[i]:\n",
    "                    rateIndex = i\n",
    "                    break\n",
    "            if nSliceToChoice[rateIndex] != 0:\n",
    "                listItemIndex.append(itemNum)\n",
    "        row = np.array(listItemIndex)\n",
    "        col = np.array([i for i in range(itemData.shape[1])])\n",
    "        itemAverageSales = itemAverageSales[row]\n",
    "        listItem = listItem[row]\n",
    "        itemData = itemData[row[:, np.newaxis], col]\n",
    "        print(itemData.shape, listItem)\n",
    "        \n",
    "        listItem = listItem.tolist() \n",
    "        index = 0\n",
    "        \n",
    "        # заполняем массив усредненными по годам недельными продажами\n",
    "        meanSaleByWeekTemp = np.zeros(salesData.shape, dtype=np.float32)\n",
    "        numWeekForSeasonal = salesData.shape[1] - 16\n",
    "        \n",
    "        def remove_trend(data):\n",
    "            \"\"\"\n",
    "               in data - (2-dim massive, row - article, col - sales by week)\n",
    "               calculate trend use week 0 - 10 and 145 - 155\n",
    "               out data - data without trend\n",
    "            \"\"\"\n",
    "            col = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155]\n",
    "            for row in range(data.shape[0]):        \n",
    "                fp = np.polyfit(col, data[row][col], 1)\n",
    "                for x in range(data.shape[1]):\n",
    "                    data[row, x] = data[row, x] - fp[0] * (x - 77)\n",
    "            return data\n",
    "\n",
    "        salesData_remove_trend = remove_trend(salesData.copy())\n",
    "        for index in range(salesData.shape[0]):\n",
    "            for iWeek in range(salesData.shape[1]):\n",
    "                counter = 0\n",
    "                x = 0.\n",
    "                if salesData_remove_trend[index, iWeek % numWeekForSeasonal] >= 0.:\n",
    "                    x += salesData_remove_trend[index, iWeek % numWeekForSeasonal]\n",
    "                    counter += 1           \n",
    "                if salesData_remove_trend[index, (iWeek + 52) % numWeekForSeasonal] >= 0.:\n",
    "                    x += salesData_remove_trend[index, (iWeek + 52) % numWeekForSeasonal]\n",
    "                    counter += 1\n",
    "                if salesData_remove_trend[index, (iWeek + 104) % numWeekForSeasonal] >= 0.:\n",
    "                    x += salesData_remove_trend[index, (iWeek + 104) % numWeekForSeasonal]\n",
    "                    counter += 1              \n",
    "                if counter > 0:    \n",
    "                    meanSaleByWeekTemp[index, iWeek] = x / counter\n",
    "                else:\n",
    "                    meanSaleByWeekTemp[index, iWeek] = -1\n",
    "        # ----------------------------------------------------------------\n",
    "        \n",
    "        # делаем случайные сдвиги данных (у нас массив значений 172, а мы формируем данные по 120 значения)\n",
    "        print('делаем случайные сдвиги данных формируя входные данные размером - {}'.format(useNumWeek)) \n",
    "        index = 0\n",
    "        for item in range(itemData.shape[0]):\n",
    "            startIndex = []\n",
    "            rateIndex = 0\n",
    "            for i in range(len(bins)):\n",
    "                if itemAverageSales[item] <= bins[i]:\n",
    "                    rateIndex = i\n",
    "                    break           \n",
    "#             if nSliceToBin[rateIndex] == 2:\n",
    "#                 startIndex = np.random.choice(52, size = (2,)) + 1\n",
    "#             elif nSliceToBin[rateIndex] == 8:\n",
    "#                 startIndex = np.random.choice(52, size = (8,)) + 1\n",
    "#             elif nSliceToBin[rateIndex] == 4:\n",
    "            startIndex = np.random.choice(52, size = (1,)) + 1        \n",
    "            for iSlice in range(nSliceToChoice[rateIndex]):\n",
    "                if iSlice != 0:\n",
    "                    itemName = listItem[item] + '_slice_' + str(iSlice)\n",
    "                    listItem.append(itemName) \n",
    "                startIndexInItemData = startIndex[iSlice]        \n",
    "                for i in range(inItemSalesData.shape[1]):\n",
    "                    inRemainderData[index, i] = (0.4 * itemData[item, 3*(i+startIndexInItemData-1) + 2] +\n",
    "                        0.6 * itemData[item, 3*(i+startIndexInItemData-1) + 3])\n",
    "                    tempRemainderData = inRemainderData[index, i] if inRemainderData[index, i] >= 1. else 1.\n",
    "                    inItemSalesData[index, i] = (itemData[item, 3*(i+startIndexInItemData-1) + 1] / \n",
    "                        np.log10(tempRemainderData + 1.))                   \n",
    "                for i in range(itemSalesData.shape[1]): \n",
    "                    j = i + startIndexInItemData - 1\n",
    "                    remainderData[index, i] = 0.4 * itemData[item, 3*j+2] + 0.6 * itemData[item, 3*j+3]\n",
    "                    tempRemainderData= remainderData[index, i] if remainderData[index, i] >= 1. else 1.\n",
    "                    itemSalesData[index, i] = itemData[item, 3*j+1] / np.log10(tempRemainderData + 1.)\n",
    "                    meanSaleByNumberWeekInYear[index, i] = meanSaleByWeekTemp[item, j]\n",
    "                index += 1\n",
    "        itemAverageSales = np.zeros(quantityData, dtype=np.float32)        \n",
    "        for i in range(itemSalesData.shape[0]):\n",
    "            itemAverageSales[i] = np.mean(itemSalesData[i][itemSalesData[i] >= 0]) \n",
    "        print('len listItem - ', len(listItem), '   shape itemSalesData - ', itemSalesData.shape)\n",
    "        # ---------------------------------------------------------------\n",
    "        \n",
    "        # Увеличиваем средние продажи при помощи параллельного переноса временного ряда \n",
    "        # на разыгрываемое значение средних продаж\n",
    "        print(\"\"\" Увеличиваем средние продажи при помощи параллельного переноса временного ряда \n",
    "        на разыгрываемое значение средних продаж \"\"\")\n",
    "        change_mean_rt4 = np.arange(0, 201, 2)\n",
    "        change_mean_rt3 = np.arange(0, 101, 1)\n",
    "        probably = np.array([0.015 - np.abs(k) / 5000 for k in range(-50, 51)]) / 1.005\n",
    "        for item in range(itemSalesData.shape[0]):\n",
    "            startIndex = []\n",
    "            rateIndex = 0\n",
    "            for i in range(len(bins)):\n",
    "                if itemAverageSales[item] <= bins[i]:\n",
    "                    rateIndex = i\n",
    "                    break\n",
    "            if rateIndex == 4 or rateIndex == 3:\n",
    "                change_mean = change_mean_rt4 if rateIndex == 4 else change_mean_rt3\n",
    "                mean_sale_value = np.random.choice(change_mean, size = (1,), p = probably) / 10.\n",
    "#                 print(mean_sale_value)\n",
    "                itemName = listItem[item] + '_add_mean'\n",
    "                listItem.append(itemName)\n",
    "                inItemSalesData_new = inItemSalesData[item] + mean_sale_value\n",
    "                inItemSalesData_new[inItemSalesData_new < 0] = 0.\n",
    "                inItemSalesData = np.vstack([inItemSalesData, inItemSalesData_new])       \n",
    "                itemSalesData_new = itemSalesData[item] + mean_sale_value\n",
    "                itemSalesData_new[itemSalesData_new < 0] = 0\n",
    "                itemSalesData = np.vstack([itemSalesData, itemSalesData_new])\n",
    "                meanSaleByNumberWeekInYear_new = meanSaleByNumberWeekInYear[item] + mean_sale_value\n",
    "                meanSaleByNumberWeekInYear_new[meanSaleByNumberWeekInYear_new < 0] = 0\n",
    "                meanSaleByNumberWeekInYear = np.vstack([meanSaleByNumberWeekInYear, meanSaleByNumberWeekInYear_new])\n",
    "        itemAverageSales = np.zeros(itemSalesData.shape[0], dtype=np.float32)        \n",
    "        for i in range(itemSalesData.shape[0]):\n",
    "            itemAverageSales[i] = np.mean(itemSalesData[i][itemSalesData[i] >= 0]) \n",
    "        print('len listItem - ', len(listItem), '   shape itemSalesData - ', itemSalesData.shape)\n",
    "        # -------------------------------------------------------------------------------\n",
    "        \n",
    "        # добавляем данные - отражение временного ряда (изменяем тренд на противоположный)\n",
    "        print('добавляем отраженные данные')\n",
    "        for item in range(itemSalesData.shape[0]):\n",
    "            itemName = listItem[item] + '_flipping'\n",
    "            listItem.append(itemName)     \n",
    "            inItemSalesData_new = np.flip(inItemSalesData[item])\n",
    "            inItemSalesData = np.vstack([inItemSalesData, inItemSalesData_new])\n",
    "            itemSalesData_new = np.flip(itemSalesData[item])\n",
    "            itemSalesData = np.vstack([itemSalesData, itemSalesData_new])\n",
    "            meanSaleByNumberWeekInYear_new = np.flip(meanSaleByNumberWeekInYear[item])\n",
    "            meanSaleByNumberWeekInYear = np.vstack([meanSaleByNumberWeekInYear, meanSaleByNumberWeekInYear_new])\n",
    "        # -------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        itemAverageSales = np.zeros(itemSalesData.shape[0], dtype=np.float32)        \n",
    "        for i in range(itemSalesData.shape[0]):\n",
    "            itemAverageSales[i] = np.mean(itemSalesData[i][itemSalesData[i] >= 0]) \n",
    "        print('len listItem - ', len(listItem), '   shape itemSalesData - ', itemSalesData.shape)\n",
    "        \n",
    "        # добавляем шум в данные по продажам\n",
    "        print('добавляем шум')\n",
    "        for item in range(itemSalesData.shape[0]):\n",
    "            for i in range(len(bins)):\n",
    "                if itemAverageSales[item] <= bins[i]:\n",
    "                    rateIndex = i\n",
    "                    break  \n",
    "            if rateIndex > 2:\n",
    "                itemName = listItem[item] + '_with_noise'\n",
    "                listItem.append(itemName) \n",
    "                # N(μ, σ^2)  σ * np.matlib.randn() + μ\n",
    "                noiseMatrix = ((0.9 * np.matlib.randn(inItemSalesData.shape[1])))\n",
    "                noiseMatrix = np.floor(np.resize(noiseMatrix, (inItemSalesData.shape[1],)) + 0.5).astype(np.int32)\n",
    "                inItemSalesData_new = inItemSalesData[item] + noiseMatrix\n",
    "                inItemSalesData_new = np.where(inItemSalesData_new < 0, 0, inItemSalesData_new)\n",
    "#                 inRemainderData = np.vstack([inRemainderData, inRemainderData[item]])\n",
    "                inItemSalesData = np.vstack([inItemSalesData, inItemSalesData_new])\n",
    "                itemSalesData = np.vstack([itemSalesData, itemSalesData[item]])\n",
    "                meanSaleByNumberWeekInYear = np.vstack([meanSaleByNumberWeekInYear, meanSaleByNumberWeekInYear[item]])\n",
    "                #print(inItemSalesData[item], noiseMatrix, inItemSalesData_new) \n",
    "        itemAverageSales = np.zeros(itemSalesData.shape[0], dtype=np.float32)        \n",
    "        for i in range(itemSalesData.shape[0]):\n",
    "            itemAverageSales[i] = np.mean(itemSalesData[i][itemSalesData[i] >= 0])\n",
    "        print('len listItem - ', len(listItem), '   shape itemSalesData - ', itemSalesData.shape)\n",
    "        # -----------------------------------------------\n",
    "        \n",
    "        # используем скользящую медиану с окном шириной 3 для представления входных данных\n",
    "        print('сглаживаем временной ряд скользящей медианой с окном шириной 3')\n",
    "        def skate_median(series, wide_window):\n",
    "            skate_median_series = []\n",
    "            for_first_median = np.sort([series[0], series[1], 3 * series[1] - 2 * series[2]])\n",
    "#             print(for_first_median)\n",
    "            for_last_median = np.sort([series[-1], series[-2], 3 * series[-2] - 2 * series[-3]])\n",
    "            skate_median_series.append(get_median(for_first_median))\n",
    "            cur_series = [series[i] for i in range(wide_window)]\n",
    "            cur_series = np.array(cur_series)\n",
    "            cur_series = np.sort(cur_series)\n",
    "#             print(cur_series)\n",
    "            n = wide_window\n",
    "            skate_median_series.append(get_median(cur_series))\n",
    "            while n < len(series):\n",
    "                temp = []\n",
    "                data_bool = 0 \n",
    "                for i, value in enumerate(cur_series):\n",
    "                    if value != series[n - wide_window]:\n",
    "                        temp.append(value)\n",
    "                    else:\n",
    "                        if data_bool:\n",
    "                            temp.append(value)             \n",
    "                        else:\n",
    "                            data_bool = 1\n",
    "                place = get_place_insert(temp, series[n]) \n",
    "                cur_series[place] = series[n]\n",
    "                for i, value in enumerate(temp):            \n",
    "                    if i < place:\n",
    "                        cur_series[i] = value\n",
    "                    else:\n",
    "                        cur_series[i+1] = value\n",
    "#                 print(cur_series)        \n",
    "                skate_median_series.append(get_median(cur_series))                              \n",
    "                n += 1 \n",
    "#             print(for_last_median)    \n",
    "            skate_median_series.append(get_median(for_last_median))                           \n",
    "            return skate_median_series\n",
    "\n",
    "        def get_median(series):\n",
    "            n = len(series)\n",
    "            if n % 2 == 0:\n",
    "                return series[n//2 - 1] + series[n//2]\n",
    "            elif n % 2 == 1:\n",
    "                return series[n//2]\n",
    "    \n",
    "        def get_place_insert(series, value):\n",
    "            left = -1\n",
    "            right = len(series)\n",
    "            while right > left + 1:\n",
    "                middle = (right + left) // 2\n",
    "                if series[middle] > value:\n",
    "                    right = middle                \n",
    "                elif series[middle] <= value:\n",
    "                    left = middle\n",
    "            return right \n",
    "#         for i in range(itemSalesData.shape[0]):\n",
    "#             inItemSalesData[i, :] = skate_median(inItemSalesData[i, :], 3)\n",
    "# #             itemSalesData[i, :] = skate_median(itemSalesData[i, :], 3)\n",
    "#             meanSaleByNumberWeekInYear[i, :] = skate_median(meanSaleByNumberWeekInYear[i, :], 3)\n",
    "        # ------------------------------------------------------------------------\n",
    "        \n",
    "        # усреднение по трем точкам \n",
    "        print('усреднение по трем точкам')\n",
    "        tSmoothingStart = time()\n",
    "        for i in range(itemSalesData.shape[0]):\n",
    "            tempData = (inItemSalesData[i, :], itemSalesData[i, :])#, inRemainderData[i, :])\n",
    "            tempInDataSales = np.empty_like(tempData[0])\n",
    "            tempDataSales = np.empty_like(tempData[1])\n",
    "#             tempDataRemainder = np.empty_like(tempData[2])\n",
    "            inLenData = inItemSalesData.shape[1]\n",
    "            lenData = itemSalesData.shape[1]\n",
    "            for iweek in range(inLenData):\n",
    "                if iweek == 0:\n",
    "                    tempInDataSales[iweek] = (tempData[0][iweek] + tempData[0][iweek+1]) / 2.   \n",
    "                    tempDataSales[iweek] = (tempData[1][iweek] + tempData[1][iweek + 1]) / 2.\n",
    "                elif iweek == (inLenData - 1):\n",
    "                    tempInDataSales[iweek] = (tempData[0][iweek-1] + tempData[0][iweek]) / 2.    \n",
    "                    tempDataSales[iweek] = (tempData[1][iweek-1] + tempData[1][iweek]) / 2.\n",
    "                else:    \n",
    "                    tempInDataSales[iweek] = (tempData[0][iweek-1] + tempData[0][iweek] + tempData[0][iweek+1]) / 3.   \n",
    "                    tempDataSales[iweek] = (tempData[1][iweek-1] + tempData[1][iweek] + tempData[1][iweek+1]) / 3. \n",
    "            inItemSalesData[i, :] = tempInDataSales[:]\n",
    "            itemSalesData[i, :] = tempDataSales[:]                                       \n",
    "        tSmoothingEnd = time()              \n",
    "        # ---------------------------------\n",
    "        \n",
    "        # добавляем перестановки соседних данных по продажам\n",
    "        print('добавляем перестановки соседних данных')\n",
    "        for item in range(itemSalesData.shape[0]):\n",
    "            for i in range(len(bins)):\n",
    "                if itemAverageSales[item] <= bins[i]:\n",
    "                    rateIndex = i\n",
    "                    break \n",
    "            if rateIndex > 2:\n",
    "                itemName = listItem[item] + '_with_shift'\n",
    "                listItem.append(itemName)\n",
    "                pos = np.random.randint(1, inItemSalesData.shape[1] + 1)\n",
    "                nElements = np.random.randint(1, 4)\n",
    "                shift = (1.2 * np.matlib.randn(1))\n",
    "                shift = np.floor(np.resize(shift, (1,)) + 0.5).astype(np.int32)[0]\n",
    "                inItemSalesData_new = inItemSalesData[item].copy()\n",
    "#                 inRemainderData_new = inRemainderData[item].copy()\n",
    "                for n in range(nElements):\n",
    "                    curPos = pos+n if pos+n < inItemSalesData.shape[1] else pos+n-inItemSalesData.shape[1]\n",
    "                    newPos = pos+shift+n if pos+shift+n < inItemSalesData.shape[1] else pos+shift+n-inItemSalesData.shape[1]\n",
    "                    inItemSalesData_new[curPos] = inItemSalesData[item][newPos]\n",
    "                    inItemSalesData_new[newPos] = inItemSalesData[item][curPos]\n",
    "#                     inRemainderData_new[curPos] = inRemainderData[item][newPos]\n",
    "#                     inRemainderData_new[newPos] = inRemainderData[item][curPos]\n",
    "#                 inRemainderData = np.vstack([inRemainderData, inRemainderData_new])             \n",
    "                inItemSalesData = np.vstack([inItemSalesData, inItemSalesData_new])\n",
    "                itemSalesData = np.vstack([itemSalesData, itemSalesData[item]])\n",
    "                meanSaleByNumberWeekInYear = np.vstack([meanSaleByNumberWeekInYear, meanSaleByNumberWeekInYear[item]])\n",
    "\n",
    "        print('len listItem - ', len(listItem), '   shape itemSalesData - ', itemSalesData.shape) \n",
    "        # --------------------------------------------------------------------------------------                \n",
    "\n",
    "        # убираем часть данных по продажам\n",
    "        print('убираем часть данных')\n",
    "        itemAverageSales = np.zeros(inItemSalesData.shape[0], dtype=np.float32)\n",
    "        for i in range(itemSalesData.shape[0]):\n",
    "            choiceData = inItemSalesData[i, :] >= 0\n",
    "            sumChoiceData = choiceData.sum()\n",
    "            itemAverageSales[i] = inItemSalesData[i][choiceData].mean() if sumChoiceData > 1 else 0.\n",
    "        rateBin = np.array([0, 1, 1, 3, 5]) \n",
    "        for item in range(itemSalesData.shape[0]):\n",
    "            for i in range(len(bins)):\n",
    "                if itemAverageSales[item] <= bins[i]:\n",
    "                    rateIndex = i\n",
    "                    break       \n",
    "            for _ in range(rateBin[rateIndex]):\n",
    "                listWeek = set()\n",
    "                numChangePoint = np.random.randint(0, 5)\n",
    "                if numChangePoint != 0:\n",
    "                    inItemSalesData_new = inItemSalesData[item, :].copy()\n",
    "                    itemSalesData_new = itemSalesData[item, :].copy()\n",
    "                    meanSaleByNumberWeekInYear_new = meanSaleByNumberWeekInYear[item, :].copy()\n",
    "                    posChangePoint = np.random.randint(0, 104, (numChangePoint,))\n",
    "                    numChangeWeek = np.random.randint(0, 4, (numChangePoint,))\n",
    "                    for k in range(numChangePoint):\n",
    "                        for nWeek in range(numChangeWeek[k]):\n",
    "                            inItemSalesData_new[(posChangePoint[k] + nWeek) % 104] = -1.\n",
    "                            listWeek.add((posChangePoint[k] + nWeek) % 104)\n",
    "                    for iWeek in listWeek:\n",
    "                        if ((iWeek + 52) % 104 in listWeek):\n",
    "                            meanSaleByNumberWeekInYear_new[iWeek] = -1.\n",
    "                    itemName = listItem[item] + '_with_reposition'\n",
    "                    listItem.append(itemName)\n",
    "                    inItemSalesData = np.vstack([inItemSalesData, inItemSalesData_new])\n",
    "                    itemSalesData = np.vstack([itemSalesData, itemSalesData_new])\n",
    "                    meanSaleByNumberWeekInYear = np.vstack([meanSaleByNumberWeekInYear, meanSaleByNumberWeekInYear_new])        \n",
    "        print('len listItem - ', len(listItem), '   shape inItemSalesData - ', inItemSalesData.shape) \n",
    "        # -------------------------------------- \n",
    "        \n",
    "        # проверка наполнения групп по продажам\n",
    "        print('проверка наполнения групп по продажам')\n",
    "        itemAverageSales = np.zeros(itemSalesData.shape[0], dtype=np.float32)\n",
    "        for i in range(itemSalesData.shape[0]):\n",
    "            choiceData = itemSalesData[i, :] >= 0\n",
    "            sumChoiceData = choiceData.sum()\n",
    "            itemAverageSales[i] = itemSalesData[i][choiceData].mean() if sumChoiceData > 1 else 0.       \n",
    "        bins = np.array([0., 0.9, 3, 8, 10000]) # первый элемент 0.25 заменен на 0 из-за шума\n",
    "        nDataInBin = np.zeros(len(bins) - 1, dtype=np.int32)\n",
    "        for i in range(len(nDataInBin)):\n",
    "            nDataInBin[i] = (itemAverageSales <= bins[i+1]).sum() - (itemAverageSales < bins[i]).sum()\n",
    "            print('[ средние продажи в интервале %.3f - %.3f ]  - товаров %5d' %(bins[i], bins[i+1], nDataInBin[i])) \n",
    "        # -----------------------------------------                     \n",
    "        \n",
    "        # замена продаж с 1 до 16 недели на -1\n",
    "        print('замена продаж с 1 недели по 16 на -1')\n",
    "        for i in range(itemSalesData.shape[0]):\n",
    "            inItemSalesData[:, :16] = -1.\n",
    "        # ------------------------------------ \n",
    "        \n",
    "        # здесь переход от логнормального распределения к нормальному \n",
    "        inItemSalesData[inItemSalesData != -1.] = args.logNormToNormData(inItemSalesData[inItemSalesData != -1.])\n",
    "        inItemSalesData[inItemSalesData == -1.] = 1e-6\n",
    "        itemSalesData = args.logNormToNormData(itemSalesData)\n",
    "        meanSaleByNumberWeekInYear[meanSaleByNumberWeekInYear != -1.] = \\\n",
    "            args.logNormToNormData(meanSaleByNumberWeekInYear[meanSaleByNumberWeekInYear != -1.])\n",
    "        meanSaleByNumberWeekInYear[meanSaleByNumberWeekInYear == -1.] = 1e-6\n",
    "        # ---------------------------------------------------------- \n",
    "        \n",
    "        # Переверот данных (из будущего в прошлое --> из прошлого в будущее)\n",
    "        inItemSalesData = np.flip(inItemSalesData, axis=1)\n",
    "        itemSalesData = np.flip(itemSalesData, axis=1)\n",
    "        meanSaleByNumberWeekInYear = np.flip(meanSaleByNumberWeekInYear, axis=1)  \n",
    "        # ------------------------------------------------------------------\n",
    "        \n",
    "        listData_in = []\n",
    "        listData_out = []\n",
    "        \n",
    "        for i in range(itemSalesData.shape[0]):            \n",
    "            listData_in.append([meanSaleByNumberWeekInYear[i, :], inItemSalesData[i,:]])\n",
    "            listData_out.append([itemSalesData[i,:]])\n",
    "            \n",
    "        listNumOfItem = np.arange(1, len(listItem)+1)      \n",
    "        dataTable_in = np.array(listData_in)\n",
    "        dataTable_in = dataTable_in.reshape(-1, inItemSalesData.shape[1])\n",
    "        print('dataTable_in.shape - ', dataTable_in.shape)\n",
    "        dataTable_out = np.array(listData_out)\n",
    "        dataTable_out = dataTable_out.reshape(-1, itemSalesData.shape[1])\n",
    "        print('dataTable_out.shape - ', dataTable_out.shape)       \n",
    "        print('NumItem - ', len(listNumOfItem))\n",
    "        iterables_in = [listNumOfItem, ['meanSaleByWeek', 'pseudoSales']]\n",
    "        iterables_out = [listNumOfItem, ['realSales']]\n",
    "        index_in = pd.MultiIndex.from_product(iterables_in, names = ['articles', 'typeData'])\n",
    "        index_out = pd.MultiIndex.from_product(iterables_out, names = ['articles', 'typeData'])      \n",
    "        columns_in = [str(inItemSalesData.shape[1] - i) + ' week ago' for i in range(inItemSalesData.shape[1])]\n",
    "        print('len columns_in -', len(columns_in))\n",
    "        columns_out = [str(itemSalesData.shape[1] - i) + ' week ago' for i in range(itemSalesData.shape[1])] \n",
    "        print('len columns_in -', len(columns_out))\n",
    "        itemSalesTable_in = pd.DataFrame(dataTable_in, index= index_in, columns = columns_in)\n",
    "        itemSalesTable_in = itemSalesTable_in.sort_index(level = 'articles')\n",
    "        display(itemSalesTable_in)\n",
    "        itemSalesTable_out = pd.DataFrame(dataTable_out, index= index_out, columns = columns_out)\n",
    "        itemSalesTable_out = itemSalesTable_out.sort_index(level = 'articles')\n",
    "        display(itemSalesTable_out)\n",
    "        itemSalesTable_in['split'] = ''\n",
    "        itemSalesTable_out['split'] = ''\n",
    "        n_total = len(set(itemSalesTable_in.reset_index()['articles'].values))\n",
    "        n_train = int(args.train_proportion * n_total + 0.5)\n",
    "        n_val = int(args.val_proportion * n_total + 0.5)\n",
    "        n_test = n_total - n_train - n_val\n",
    "        print(n_total, n_train, n_val, n_test)    \n",
    "        t1 = time()\n",
    "        listTrain_in = n_train*[['train','train']]\n",
    "        listTrain_out = n_train*[['train']]\n",
    "        listVal_in = n_val*[['val','val']]\n",
    "        listVal_out = n_val*[['val']]\n",
    "        listTest_in = n_test*[['test','test']]\n",
    "        listTest_out = n_test*[['test']]\n",
    "        \n",
    "        listValue_in = []\n",
    "        listValue_in.extend(listTrain_in)\n",
    "        listValue_in.extend(listVal_in)\n",
    "        listValue_in.extend(listTest_in)\n",
    "        listValue_in = pd.DataFrame(listValue_in)\n",
    "        print('shape listValue_in - ', listValue_in.shape)\n",
    "        display(listValue_in)\n",
    "        listValue_out = []\n",
    "        listValue_out.extend(listTrain_out)\n",
    "        listValue_out.extend(listVal_out)\n",
    "        listValue_out.extend(listTest_out)\n",
    "        listValue_out = pd.DataFrame(listValue_out)\n",
    "        print('shape listValue_out - ', listValue_out.shape)\n",
    "        \n",
    "        mix_up = np.random.permutation(len(listValue_in))\n",
    "        permuteListItem_in = listValue_in.take(mix_up)\n",
    "        listValue_in = permuteListItem_in\n",
    "#         display(listValue_in)\n",
    "        permuteListItem_out = listValue_out.take(mix_up)\n",
    "        listValue_out = permuteListItem_out\n",
    "#         display(listValue_out)\n",
    "        \n",
    "        t2 = time()\n",
    "        print('t2 - t1 = %f' %(t2-t1))\n",
    "#         print('shape itemSalesTable_in - ', itemSalesTable_in.shape)\n",
    "#         print('shape listValue_in - ', listValue_in.shape)\n",
    "        itemSalesTable_in.loc[idx[:,['meanSaleByWeek']], idx['split']] = listValue_in[:][0].values\n",
    "        itemSalesTable_in.loc[idx[:,['pseudoSales']], idx['split']] = listValue_in[:][1].values\n",
    "        itemSalesTable_out.loc[idx[:,['realSales']], idx['split']] = listValue_out[:][0].values\n",
    "        t3 = time()\n",
    "        print('t3 - t2 = %f' %(t3-t2))\n",
    "        display(itemSalesTable_in)  \n",
    "        display(itemSalesTable_out)\n",
    "        return cls((itemSalesTable_in, itemSalesTable_out))\n",
    "    \n",
    "    def get_vector_data(self, index, tableData_df, data_bool = True):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if data_bool:\n",
    "            item = tableData_df.index[self.numData_Substring * index][0]\n",
    "            inputData = tableData_df.loc[idx[:, ['meanSaleByWeek', 'pseudoSales']], idx['120 week ago':'1 week ago']]\n",
    "            dataMassive = inputData.loc[idx[item, ['meanSaleByWeek', 'pseudoSales']], idx[:]].values\n",
    "        else :\n",
    "            item = tableData_df.index[index][0]\n",
    "            factData = tableData_df.loc[idx[:, ['realSales']], idx['120 week ago':'1 week ago']]\n",
    "            dataMassive = factData.loc[idx[item, :], idx[:]].values\n",
    "        return dataMassive\n",
    "    \n",
    "    def set_split(self, split='train'):\n",
    "        \"\"\"\n",
    "            Выбор фрагментов набора данных по столбцу из объекта dataframe\n",
    "            Аргументы:\n",
    "                split (str): 'train' (обучающий), 'val' (проверочный), 'test' (контрольный)\n",
    "        \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_in_df, self._target_out_df, self._target_size = self._lookup_dict[split]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "            Аргументы:\n",
    "                index (int): индекс точки данных\n",
    "                \n",
    "            Возвращает:\n",
    "                словарь признаков (x_data) и метки (y_target) точки данных\n",
    "        \"\"\"\n",
    "        \n",
    "        inputData_vector = self.get_vector_data(index, self._target_in_df, True)\n",
    "        factData_vector = self.get_vector_data(index, self._target_out_df, False)\n",
    "        \n",
    "        return {'x_data' : inputData_vector, 'y_target' : factData_vector}\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allWeek 172, useNumWeek 120\n",
      "(3546,)\n",
      "[ средние продажи в интервале 0.000 - 0.300 ]  - товаров  2489\n",
      "[ средние продажи в интервале 0.300 - 0.900 ]  - товаров   725\n",
      "[ средние продажи в интервале 0.900 - 3.000 ]  - товаров   291\n",
      "[ средние продажи в интервале 3.000 - 8.000 ]  - товаров    25\n",
      "[ средние продажи в интервале 8.000 - 10000.000 ]  - товаров    16\n",
      "quantity of example -  1057\n",
      "(3546, 517) (1057, 120) (1057, 120) (1057, 120) (1057, 120)\n",
      "(1057, 517) ['Д59510' '94254' 'A4368H' ... '9412' 'M-2332' 'А6473']\n",
      "делаем случайные сдвиги данных формируя входные данные размером - 120\n",
      "len listItem -  1057    shape itemSalesData -  (1057, 120)\n",
      " Увеличиваем средние продажи при помощи параллельного переноса временного ряда \n",
      "        на разыгрываемое значение средних продаж \n",
      "len listItem -  1096    shape itemSalesData -  (1096, 120)\n",
      "добавляем отраженные данные\n",
      "len listItem -  2192    shape itemSalesData -  (2192, 120)\n",
      "добавляем шум\n",
      "len listItem -  2348    shape itemSalesData -  (2348, 120)\n",
      "сглаживаем временной ряд скользящей медианой с окном шириной 3\n",
      "усреднение по трем точкам\n",
      "добавляем перестановки соседних данных\n",
      "len listItem -  2660    shape itemSalesData -  (2660, 120)\n",
      "убираем часть данных\n",
      "len listItem -  6223    shape inItemSalesData -  (6223, 120)\n",
      "проверка наполнения групп по продажам\n",
      "[ средние продажи в интервале 0.000 - 0.900 ]  - товаров  2493\n",
      "[ средние продажи в интервале 0.900 - 3.000 ]  - товаров  1017\n",
      "[ средние продажи в интервале 3.000 - 8.000 ]  - товаров   882\n",
      "[ средние продажи в интервале 8.000 - 10000.000 ]  - товаров  1831\n",
      "замена продаж с 1 недели по 16 на -1\n",
      "dataTable_in.shape -  (12446, 120)\n",
      "dataTable_out.shape -  (6223, 120)\n",
      "NumItem -  6223\n",
      "len columns_in - 120\n",
      "len columns_in - 120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>120 week ago</th>\n",
       "      <th>119 week ago</th>\n",
       "      <th>118 week ago</th>\n",
       "      <th>117 week ago</th>\n",
       "      <th>116 week ago</th>\n",
       "      <th>115 week ago</th>\n",
       "      <th>114 week ago</th>\n",
       "      <th>113 week ago</th>\n",
       "      <th>112 week ago</th>\n",
       "      <th>111 week ago</th>\n",
       "      <th>...</th>\n",
       "      <th>10 week ago</th>\n",
       "      <th>9 week ago</th>\n",
       "      <th>8 week ago</th>\n",
       "      <th>7 week ago</th>\n",
       "      <th>6 week ago</th>\n",
       "      <th>5 week ago</th>\n",
       "      <th>4 week ago</th>\n",
       "      <th>3 week ago</th>\n",
       "      <th>2 week ago</th>\n",
       "      <th>1 week ago</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>articles</th>\n",
       "      <th>typeData</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>meanSaleByWeek</th>\n",
       "      <td>1.004901</td>\n",
       "      <td>1.364684</td>\n",
       "      <td>1.004575</td>\n",
       "      <td>1.004412</td>\n",
       "      <td>1.008480</td>\n",
       "      <td>1.008318</td>\n",
       "      <td>1.008155</td>\n",
       "      <td>1.007993</td>\n",
       "      <td>1.007830</td>\n",
       "      <td>1.163938</td>\n",
       "      <td>...</td>\n",
       "      <td>1.008155</td>\n",
       "      <td>1.007993</td>\n",
       "      <td>1.007830</td>\n",
       "      <td>1.163938</td>\n",
       "      <td>1.007505</td>\n",
       "      <td>1.007343</td>\n",
       "      <td>1.007180</td>\n",
       "      <td>1.007018</td>\n",
       "      <td>1.006855</td>\n",
       "      <td>1.006692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pseudoSales</th>\n",
       "      <td>1.162653</td>\n",
       "      <td>1.111320</td>\n",
       "      <td>1.215417</td>\n",
       "      <td>1.115671</td>\n",
       "      <td>1.115671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>meanSaleByWeek</th>\n",
       "      <td>1.109369</td>\n",
       "      <td>1.278372</td>\n",
       "      <td>1.197730</td>\n",
       "      <td>1.196680</td>\n",
       "      <td>1.033885</td>\n",
       "      <td>1.110992</td>\n",
       "      <td>1.275786</td>\n",
       "      <td>1.142640</td>\n",
       "      <td>1.018813</td>\n",
       "      <td>1.019503</td>\n",
       "      <td>...</td>\n",
       "      <td>1.275786</td>\n",
       "      <td>1.142640</td>\n",
       "      <td>1.018813</td>\n",
       "      <td>1.019503</td>\n",
       "      <td>1.020193</td>\n",
       "      <td>1.020882</td>\n",
       "      <td>1.272323</td>\n",
       "      <td>1.022258</td>\n",
       "      <td>1.022946</td>\n",
       "      <td>1.374266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pseudoSales</th>\n",
       "      <td>1.148691</td>\n",
       "      <td>1.193528</td>\n",
       "      <td>1.193528</td>\n",
       "      <td>1.101335</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>meanSaleByWeek</th>\n",
       "      <td>1.458459</td>\n",
       "      <td>1.364807</td>\n",
       "      <td>1.231527</td>\n",
       "      <td>1.754713</td>\n",
       "      <td>1.743637</td>\n",
       "      <td>1.499401</td>\n",
       "      <td>1.340038</td>\n",
       "      <td>1.436232</td>\n",
       "      <td>1.230517</td>\n",
       "      <td>1.357727</td>\n",
       "      <td>...</td>\n",
       "      <td>1.340038</td>\n",
       "      <td>1.436232</td>\n",
       "      <td>1.230517</td>\n",
       "      <td>1.357727</td>\n",
       "      <td>1.487932</td>\n",
       "      <td>1.428296</td>\n",
       "      <td>1.602883</td>\n",
       "      <td>1.331203</td>\n",
       "      <td>1.329948</td>\n",
       "      <td>1.220094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <th>pseudoSales</th>\n",
       "      <td>2.613025</td>\n",
       "      <td>2.531016</td>\n",
       "      <td>2.435216</td>\n",
       "      <td>2.375056</td>\n",
       "      <td>2.352668</td>\n",
       "      <td>2.287158</td>\n",
       "      <td>2.352668</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.411237</td>\n",
       "      <td>2.434000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6222</th>\n",
       "      <th>meanSaleByWeek</th>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>...</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pseudoSales</th>\n",
       "      <td>2.613025</td>\n",
       "      <td>2.531016</td>\n",
       "      <td>2.435216</td>\n",
       "      <td>2.375056</td>\n",
       "      <td>2.352668</td>\n",
       "      <td>2.287158</td>\n",
       "      <td>2.352668</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.411237</td>\n",
       "      <td>2.434000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6223</th>\n",
       "      <th>meanSaleByWeek</th>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>...</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pseudoSales</th>\n",
       "      <td>2.613025</td>\n",
       "      <td>2.531016</td>\n",
       "      <td>2.435216</td>\n",
       "      <td>2.375056</td>\n",
       "      <td>2.352668</td>\n",
       "      <td>2.287158</td>\n",
       "      <td>2.352668</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.411237</td>\n",
       "      <td>2.434000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12446 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         120 week ago  119 week ago  118 week ago  \\\n",
       "articles typeData                                                   \n",
       "1        meanSaleByWeek      1.004901      1.364684      1.004575   \n",
       "         pseudoSales         1.162653      1.111320      1.215417   \n",
       "2        meanSaleByWeek      1.109369      1.278372      1.197730   \n",
       "         pseudoSales         1.148691      1.193528      1.193528   \n",
       "3        meanSaleByWeek      1.458459      1.364807      1.231527   \n",
       "...                               ...           ...           ...   \n",
       "6221     pseudoSales         2.613025      2.531016      2.435216   \n",
       "6222     meanSaleByWeek      2.343562      2.343562      2.343562   \n",
       "         pseudoSales         2.613025      2.531016      2.435216   \n",
       "6223     meanSaleByWeek      2.343562      2.343562      2.343562   \n",
       "         pseudoSales         2.613025      2.531016      2.435216   \n",
       "\n",
       "                         117 week ago  116 week ago  115 week ago  \\\n",
       "articles typeData                                                   \n",
       "1        meanSaleByWeek      1.004412      1.008480      1.008318   \n",
       "         pseudoSales         1.115671      1.115671      1.000000   \n",
       "2        meanSaleByWeek      1.196680      1.033885      1.110992   \n",
       "         pseudoSales         1.101335      1.101542      1.101542   \n",
       "3        meanSaleByWeek      1.754713      1.743637      1.499401   \n",
       "...                               ...           ...           ...   \n",
       "6221     pseudoSales         2.375056      2.352668      2.287158   \n",
       "6222     meanSaleByWeek      2.343562      2.343562      2.343562   \n",
       "         pseudoSales         2.375056      2.352668      2.287158   \n",
       "6223     meanSaleByWeek      2.343562      2.343562      2.343562   \n",
       "         pseudoSales         2.375056      2.352668      2.287158   \n",
       "\n",
       "                         114 week ago  113 week ago  112 week ago  \\\n",
       "articles typeData                                                   \n",
       "1        meanSaleByWeek      1.008155      1.007993      1.007830   \n",
       "         pseudoSales         1.000000      1.000000      1.000000   \n",
       "2        meanSaleByWeek      1.275786      1.142640      1.018813   \n",
       "         pseudoSales         1.101542      1.101542      1.101542   \n",
       "3        meanSaleByWeek      1.340038      1.436232      1.230517   \n",
       "...                               ...           ...           ...   \n",
       "6221     pseudoSales         2.352668      2.343562      2.411237   \n",
       "6222     meanSaleByWeek      2.343562      2.343562      2.343562   \n",
       "         pseudoSales         2.352668      2.343562      2.411237   \n",
       "6223     meanSaleByWeek      2.343562      2.343562      2.343562   \n",
       "         pseudoSales         2.352668      2.343562      2.411237   \n",
       "\n",
       "                         111 week ago  ...  10 week ago  9 week ago  \\\n",
       "articles typeData                      ...                            \n",
       "1        meanSaleByWeek      1.163938  ...     1.008155    1.007993   \n",
       "         pseudoSales         1.000000  ...     0.000001    0.000001   \n",
       "2        meanSaleByWeek      1.019503  ...     1.275786    1.142640   \n",
       "         pseudoSales         1.101542  ...     0.000001    0.000001   \n",
       "3        meanSaleByWeek      1.357727  ...     1.340038    1.436232   \n",
       "...                               ...  ...          ...         ...   \n",
       "6221     pseudoSales         2.434000  ...     0.000001    0.000001   \n",
       "6222     meanSaleByWeek      2.343562  ...     2.343562    2.343562   \n",
       "         pseudoSales         2.434000  ...     0.000001    0.000001   \n",
       "6223     meanSaleByWeek      2.343562  ...     2.343562    2.343562   \n",
       "         pseudoSales         2.434000  ...     0.000001    0.000001   \n",
       "\n",
       "                         8 week ago  7 week ago  6 week ago  5 week ago  \\\n",
       "articles typeData                                                         \n",
       "1        meanSaleByWeek    1.007830    1.163938    1.007505    1.007343   \n",
       "         pseudoSales       0.000001    0.000001    0.000001    0.000001   \n",
       "2        meanSaleByWeek    1.018813    1.019503    1.020193    1.020882   \n",
       "         pseudoSales       0.000001    0.000001    0.000001    0.000001   \n",
       "3        meanSaleByWeek    1.230517    1.357727    1.487932    1.428296   \n",
       "...                             ...         ...         ...         ...   \n",
       "6221     pseudoSales       0.000001    0.000001    0.000001    0.000001   \n",
       "6222     meanSaleByWeek    2.343562    2.343562    2.343562    2.343562   \n",
       "         pseudoSales       0.000001    0.000001    0.000001    0.000001   \n",
       "6223     meanSaleByWeek    2.343562    2.343562    2.343562    2.343562   \n",
       "         pseudoSales       0.000001    0.000001    0.000001    0.000001   \n",
       "\n",
       "                         4 week ago  3 week ago  2 week ago  1 week ago  \n",
       "articles typeData                                                        \n",
       "1        meanSaleByWeek    1.007180    1.007018    1.006855    1.006692  \n",
       "         pseudoSales       0.000001    0.000001    0.000001    0.000001  \n",
       "2        meanSaleByWeek    1.272323    1.022258    1.022946    1.374266  \n",
       "         pseudoSales       0.000001    0.000001    0.000001    0.000001  \n",
       "3        meanSaleByWeek    1.602883    1.331203    1.329948    1.220094  \n",
       "...                             ...         ...         ...         ...  \n",
       "6221     pseudoSales       0.000001    0.000001    0.000001    0.000001  \n",
       "6222     meanSaleByWeek    2.343562    2.343562    2.343562    2.343562  \n",
       "         pseudoSales       0.000001    0.000001    0.000001    0.000001  \n",
       "6223     meanSaleByWeek    2.343562    2.343562    2.343562    2.343562  \n",
       "         pseudoSales       0.000001    0.000001    0.000001    0.000001  \n",
       "\n",
       "[12446 rows x 120 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>120 week ago</th>\n",
       "      <th>119 week ago</th>\n",
       "      <th>118 week ago</th>\n",
       "      <th>117 week ago</th>\n",
       "      <th>116 week ago</th>\n",
       "      <th>115 week ago</th>\n",
       "      <th>114 week ago</th>\n",
       "      <th>113 week ago</th>\n",
       "      <th>112 week ago</th>\n",
       "      <th>111 week ago</th>\n",
       "      <th>...</th>\n",
       "      <th>10 week ago</th>\n",
       "      <th>9 week ago</th>\n",
       "      <th>8 week ago</th>\n",
       "      <th>7 week ago</th>\n",
       "      <th>6 week ago</th>\n",
       "      <th>5 week ago</th>\n",
       "      <th>4 week ago</th>\n",
       "      <th>3 week ago</th>\n",
       "      <th>2 week ago</th>\n",
       "      <th>1 week ago</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>articles</th>\n",
       "      <th>typeData</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>realSales</th>\n",
       "      <td>1.162653</td>\n",
       "      <td>1.111320</td>\n",
       "      <td>1.215417</td>\n",
       "      <td>1.115671</td>\n",
       "      <td>1.115671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>realSales</th>\n",
       "      <td>1.148691</td>\n",
       "      <td>1.193528</td>\n",
       "      <td>1.193528</td>\n",
       "      <td>1.101335</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>...</td>\n",
       "      <td>1.085774</td>\n",
       "      <td>1.085774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>realSales</th>\n",
       "      <td>1.275862</td>\n",
       "      <td>1.192088</td>\n",
       "      <td>1.275152</td>\n",
       "      <td>1.424745</td>\n",
       "      <td>1.492586</td>\n",
       "      <td>1.353890</td>\n",
       "      <td>1.101963</td>\n",
       "      <td>1.103052</td>\n",
       "      <td>1.103052</td>\n",
       "      <td>1.196674</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>realSales</th>\n",
       "      <td>1.137846</td>\n",
       "      <td>1.093975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.093552</td>\n",
       "      <td>1.093552</td>\n",
       "      <td>1.093552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.135495</td>\n",
       "      <td>1.264432</td>\n",
       "      <td>1.264432</td>\n",
       "      <td>1.146338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>realSales</th>\n",
       "      <td>1.307902</td>\n",
       "      <td>1.306110</td>\n",
       "      <td>1.211480</td>\n",
       "      <td>1.210080</td>\n",
       "      <td>1.383333</td>\n",
       "      <td>1.467296</td>\n",
       "      <td>1.391805</td>\n",
       "      <td>1.336528</td>\n",
       "      <td>1.240253</td>\n",
       "      <td>1.240253</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.093904</td>\n",
       "      <td>1.093904</td>\n",
       "      <td>1.093904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.098540</td>\n",
       "      <td>1.098540</td>\n",
       "      <td>1.188401</td>\n",
       "      <td>1.144653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <th>realSales</th>\n",
       "      <td>2.575680</td>\n",
       "      <td>2.504132</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.440700</td>\n",
       "      <td>2.544569</td>\n",
       "      <td>...</td>\n",
       "      <td>2.696151</td>\n",
       "      <td>2.730514</td>\n",
       "      <td>2.904503</td>\n",
       "      <td>2.863093</td>\n",
       "      <td>2.933092</td>\n",
       "      <td>2.829429</td>\n",
       "      <td>2.870143</td>\n",
       "      <td>2.876531</td>\n",
       "      <td>2.953212</td>\n",
       "      <td>3.037318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <th>realSales</th>\n",
       "      <td>2.575680</td>\n",
       "      <td>2.504132</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.440700</td>\n",
       "      <td>2.544569</td>\n",
       "      <td>...</td>\n",
       "      <td>2.696151</td>\n",
       "      <td>2.730514</td>\n",
       "      <td>2.904503</td>\n",
       "      <td>2.863093</td>\n",
       "      <td>2.933092</td>\n",
       "      <td>2.829429</td>\n",
       "      <td>2.870143</td>\n",
       "      <td>2.876531</td>\n",
       "      <td>2.953212</td>\n",
       "      <td>3.037318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <th>realSales</th>\n",
       "      <td>2.575680</td>\n",
       "      <td>2.504132</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.440700</td>\n",
       "      <td>2.544569</td>\n",
       "      <td>...</td>\n",
       "      <td>2.696151</td>\n",
       "      <td>2.730514</td>\n",
       "      <td>2.904503</td>\n",
       "      <td>2.863093</td>\n",
       "      <td>2.933092</td>\n",
       "      <td>2.829429</td>\n",
       "      <td>2.870143</td>\n",
       "      <td>2.876531</td>\n",
       "      <td>2.953212</td>\n",
       "      <td>3.037318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <th>realSales</th>\n",
       "      <td>2.575680</td>\n",
       "      <td>2.504132</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.440700</td>\n",
       "      <td>2.544569</td>\n",
       "      <td>...</td>\n",
       "      <td>2.696151</td>\n",
       "      <td>2.730514</td>\n",
       "      <td>2.904503</td>\n",
       "      <td>2.863093</td>\n",
       "      <td>2.933092</td>\n",
       "      <td>2.829429</td>\n",
       "      <td>2.870143</td>\n",
       "      <td>2.876531</td>\n",
       "      <td>2.953212</td>\n",
       "      <td>3.037318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <th>realSales</th>\n",
       "      <td>2.575680</td>\n",
       "      <td>2.504132</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.440700</td>\n",
       "      <td>2.544569</td>\n",
       "      <td>...</td>\n",
       "      <td>2.696151</td>\n",
       "      <td>2.730514</td>\n",
       "      <td>2.904503</td>\n",
       "      <td>2.863093</td>\n",
       "      <td>2.933092</td>\n",
       "      <td>2.829429</td>\n",
       "      <td>2.870143</td>\n",
       "      <td>2.876531</td>\n",
       "      <td>2.953212</td>\n",
       "      <td>3.037318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6223 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    120 week ago  119 week ago  118 week ago  117 week ago  \\\n",
       "articles typeData                                                            \n",
       "1        realSales      1.162653      1.111320      1.215417      1.115671   \n",
       "2        realSales      1.148691      1.193528      1.193528      1.101335   \n",
       "3        realSales      1.275862      1.192088      1.275152      1.424745   \n",
       "4        realSales      1.137846      1.093975      1.000000      1.000000   \n",
       "5        realSales      1.307902      1.306110      1.211480      1.210080   \n",
       "...                          ...           ...           ...           ...   \n",
       "6219     realSales      2.575680      2.504132      2.343562      2.343562   \n",
       "6220     realSales      2.575680      2.504132      2.343562      2.343562   \n",
       "6221     realSales      2.575680      2.504132      2.343562      2.343562   \n",
       "6222     realSales      2.575680      2.504132      2.343562      2.343562   \n",
       "6223     realSales      2.575680      2.504132      2.343562      2.343562   \n",
       "\n",
       "                    116 week ago  115 week ago  114 week ago  113 week ago  \\\n",
       "articles typeData                                                            \n",
       "1        realSales      1.115671      1.000000      1.000000      1.000000   \n",
       "2        realSales      1.101542      1.101542      1.101542      1.101542   \n",
       "3        realSales      1.492586      1.353890      1.101963      1.103052   \n",
       "4        realSales      1.000000      1.093552      1.093552      1.093552   \n",
       "5        realSales      1.383333      1.467296      1.391805      1.336528   \n",
       "...                          ...           ...           ...           ...   \n",
       "6219     realSales      2.383881      2.383881      2.383881      2.343562   \n",
       "6220     realSales      2.383881      2.383881      2.383881      2.343562   \n",
       "6221     realSales      2.383881      2.383881      2.383881      2.343562   \n",
       "6222     realSales      2.383881      2.383881      2.383881      2.343562   \n",
       "6223     realSales      2.383881      2.383881      2.383881      2.343562   \n",
       "\n",
       "                    112 week ago  111 week ago  ...  10 week ago  9 week ago  \\\n",
       "articles typeData                               ...                            \n",
       "1        realSales      1.000000      1.000000  ...     1.000000    1.000000   \n",
       "2        realSales      1.101542      1.101542  ...     1.085774    1.085774   \n",
       "3        realSales      1.103052      1.196674  ...     1.000000    1.000000   \n",
       "4        realSales      1.000000      1.000000  ...     1.000000    1.000000   \n",
       "5        realSales      1.240253      1.240253  ...     1.000000    1.093904   \n",
       "...                          ...           ...  ...          ...         ...   \n",
       "6219     realSales      2.440700      2.544569  ...     2.696151    2.730514   \n",
       "6220     realSales      2.440700      2.544569  ...     2.696151    2.730514   \n",
       "6221     realSales      2.440700      2.544569  ...     2.696151    2.730514   \n",
       "6222     realSales      2.440700      2.544569  ...     2.696151    2.730514   \n",
       "6223     realSales      2.440700      2.544569  ...     2.696151    2.730514   \n",
       "\n",
       "                    8 week ago  7 week ago  6 week ago  5 week ago  \\\n",
       "articles typeData                                                    \n",
       "1        realSales    1.000000    1.000000    1.000000    1.000000   \n",
       "2        realSales    1.000000    1.000000    1.000000    1.000000   \n",
       "3        realSales    1.000000    1.000000    1.000000    1.000000   \n",
       "4        realSales    1.135495    1.264432    1.264432    1.146338   \n",
       "5        realSales    1.093904    1.093904    1.000000    1.000000   \n",
       "...                        ...         ...         ...         ...   \n",
       "6219     realSales    2.904503    2.863093    2.933092    2.829429   \n",
       "6220     realSales    2.904503    2.863093    2.933092    2.829429   \n",
       "6221     realSales    2.904503    2.863093    2.933092    2.829429   \n",
       "6222     realSales    2.904503    2.863093    2.933092    2.829429   \n",
       "6223     realSales    2.904503    2.863093    2.933092    2.829429   \n",
       "\n",
       "                    4 week ago  3 week ago  2 week ago  1 week ago  \n",
       "articles typeData                                                   \n",
       "1        realSales    1.000000    1.000000    1.000000    1.000000  \n",
       "2        realSales    1.000000    1.000000    1.000000    1.000000  \n",
       "3        realSales    1.000000    1.000000    1.000000    1.000000  \n",
       "4        realSales    1.000000    1.000000    1.000000    1.000000  \n",
       "5        realSales    1.098540    1.098540    1.188401    1.144653  \n",
       "...                        ...         ...         ...         ...  \n",
       "6219     realSales    2.870143    2.876531    2.953212    3.037318  \n",
       "6220     realSales    2.870143    2.876531    2.953212    3.037318  \n",
       "6221     realSales    2.870143    2.876531    2.953212    3.037318  \n",
       "6222     realSales    2.870143    2.876531    2.953212    3.037318  \n",
       "6223     realSales    2.870143    2.876531    2.953212    3.037318  \n",
       "\n",
       "[6223 rows x 120 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6223 31 31 6161\n",
      "shape listValue_in -  (6223, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6223 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1\n",
       "0     train  train\n",
       "1     train  train\n",
       "2     train  train\n",
       "3     train  train\n",
       "4     train  train\n",
       "...     ...    ...\n",
       "6218   test   test\n",
       "6219   test   test\n",
       "6220   test   test\n",
       "6221   test   test\n",
       "6222   test   test\n",
       "\n",
       "[6223 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape listValue_out -  (6223, 1)\n",
      "t2 - t1 = 0.008980\n",
      "t3 - t2 = 0.005980\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>120 week ago</th>\n",
       "      <th>119 week ago</th>\n",
       "      <th>118 week ago</th>\n",
       "      <th>117 week ago</th>\n",
       "      <th>116 week ago</th>\n",
       "      <th>115 week ago</th>\n",
       "      <th>114 week ago</th>\n",
       "      <th>113 week ago</th>\n",
       "      <th>112 week ago</th>\n",
       "      <th>111 week ago</th>\n",
       "      <th>...</th>\n",
       "      <th>9 week ago</th>\n",
       "      <th>8 week ago</th>\n",
       "      <th>7 week ago</th>\n",
       "      <th>6 week ago</th>\n",
       "      <th>5 week ago</th>\n",
       "      <th>4 week ago</th>\n",
       "      <th>3 week ago</th>\n",
       "      <th>2 week ago</th>\n",
       "      <th>1 week ago</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>articles</th>\n",
       "      <th>typeData</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>meanSaleByWeek</th>\n",
       "      <td>1.004901</td>\n",
       "      <td>1.364684</td>\n",
       "      <td>1.004575</td>\n",
       "      <td>1.004412</td>\n",
       "      <td>1.008480</td>\n",
       "      <td>1.008318</td>\n",
       "      <td>1.008155</td>\n",
       "      <td>1.007993</td>\n",
       "      <td>1.007830</td>\n",
       "      <td>1.163938</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007993</td>\n",
       "      <td>1.007830</td>\n",
       "      <td>1.163938</td>\n",
       "      <td>1.007505</td>\n",
       "      <td>1.007343</td>\n",
       "      <td>1.007180</td>\n",
       "      <td>1.007018</td>\n",
       "      <td>1.006855</td>\n",
       "      <td>1.006692</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pseudoSales</th>\n",
       "      <td>1.162653</td>\n",
       "      <td>1.111320</td>\n",
       "      <td>1.215417</td>\n",
       "      <td>1.115671</td>\n",
       "      <td>1.115671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>meanSaleByWeek</th>\n",
       "      <td>1.109369</td>\n",
       "      <td>1.278372</td>\n",
       "      <td>1.197730</td>\n",
       "      <td>1.196680</td>\n",
       "      <td>1.033885</td>\n",
       "      <td>1.110992</td>\n",
       "      <td>1.275786</td>\n",
       "      <td>1.142640</td>\n",
       "      <td>1.018813</td>\n",
       "      <td>1.019503</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142640</td>\n",
       "      <td>1.018813</td>\n",
       "      <td>1.019503</td>\n",
       "      <td>1.020193</td>\n",
       "      <td>1.020882</td>\n",
       "      <td>1.272323</td>\n",
       "      <td>1.022258</td>\n",
       "      <td>1.022946</td>\n",
       "      <td>1.374266</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pseudoSales</th>\n",
       "      <td>1.148691</td>\n",
       "      <td>1.193528</td>\n",
       "      <td>1.193528</td>\n",
       "      <td>1.101335</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>meanSaleByWeek</th>\n",
       "      <td>1.458459</td>\n",
       "      <td>1.364807</td>\n",
       "      <td>1.231527</td>\n",
       "      <td>1.754713</td>\n",
       "      <td>1.743637</td>\n",
       "      <td>1.499401</td>\n",
       "      <td>1.340038</td>\n",
       "      <td>1.436232</td>\n",
       "      <td>1.230517</td>\n",
       "      <td>1.357727</td>\n",
       "      <td>...</td>\n",
       "      <td>1.436232</td>\n",
       "      <td>1.230517</td>\n",
       "      <td>1.357727</td>\n",
       "      <td>1.487932</td>\n",
       "      <td>1.428296</td>\n",
       "      <td>1.602883</td>\n",
       "      <td>1.331203</td>\n",
       "      <td>1.329948</td>\n",
       "      <td>1.220094</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <th>pseudoSales</th>\n",
       "      <td>2.613025</td>\n",
       "      <td>2.531016</td>\n",
       "      <td>2.435216</td>\n",
       "      <td>2.375056</td>\n",
       "      <td>2.352668</td>\n",
       "      <td>2.287158</td>\n",
       "      <td>2.352668</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.411237</td>\n",
       "      <td>2.434000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6222</th>\n",
       "      <th>meanSaleByWeek</th>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>...</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pseudoSales</th>\n",
       "      <td>2.613025</td>\n",
       "      <td>2.531016</td>\n",
       "      <td>2.435216</td>\n",
       "      <td>2.375056</td>\n",
       "      <td>2.352668</td>\n",
       "      <td>2.287158</td>\n",
       "      <td>2.352668</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.411237</td>\n",
       "      <td>2.434000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6223</th>\n",
       "      <th>meanSaleByWeek</th>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>...</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pseudoSales</th>\n",
       "      <td>2.613025</td>\n",
       "      <td>2.531016</td>\n",
       "      <td>2.435216</td>\n",
       "      <td>2.375056</td>\n",
       "      <td>2.352668</td>\n",
       "      <td>2.287158</td>\n",
       "      <td>2.352668</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.411237</td>\n",
       "      <td>2.434000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12446 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         120 week ago  119 week ago  118 week ago  \\\n",
       "articles typeData                                                   \n",
       "1        meanSaleByWeek      1.004901      1.364684      1.004575   \n",
       "         pseudoSales         1.162653      1.111320      1.215417   \n",
       "2        meanSaleByWeek      1.109369      1.278372      1.197730   \n",
       "         pseudoSales         1.148691      1.193528      1.193528   \n",
       "3        meanSaleByWeek      1.458459      1.364807      1.231527   \n",
       "...                               ...           ...           ...   \n",
       "6221     pseudoSales         2.613025      2.531016      2.435216   \n",
       "6222     meanSaleByWeek      2.343562      2.343562      2.343562   \n",
       "         pseudoSales         2.613025      2.531016      2.435216   \n",
       "6223     meanSaleByWeek      2.343562      2.343562      2.343562   \n",
       "         pseudoSales         2.613025      2.531016      2.435216   \n",
       "\n",
       "                         117 week ago  116 week ago  115 week ago  \\\n",
       "articles typeData                                                   \n",
       "1        meanSaleByWeek      1.004412      1.008480      1.008318   \n",
       "         pseudoSales         1.115671      1.115671      1.000000   \n",
       "2        meanSaleByWeek      1.196680      1.033885      1.110992   \n",
       "         pseudoSales         1.101335      1.101542      1.101542   \n",
       "3        meanSaleByWeek      1.754713      1.743637      1.499401   \n",
       "...                               ...           ...           ...   \n",
       "6221     pseudoSales         2.375056      2.352668      2.287158   \n",
       "6222     meanSaleByWeek      2.343562      2.343562      2.343562   \n",
       "         pseudoSales         2.375056      2.352668      2.287158   \n",
       "6223     meanSaleByWeek      2.343562      2.343562      2.343562   \n",
       "         pseudoSales         2.375056      2.352668      2.287158   \n",
       "\n",
       "                         114 week ago  113 week ago  112 week ago  \\\n",
       "articles typeData                                                   \n",
       "1        meanSaleByWeek      1.008155      1.007993      1.007830   \n",
       "         pseudoSales         1.000000      1.000000      1.000000   \n",
       "2        meanSaleByWeek      1.275786      1.142640      1.018813   \n",
       "         pseudoSales         1.101542      1.101542      1.101542   \n",
       "3        meanSaleByWeek      1.340038      1.436232      1.230517   \n",
       "...                               ...           ...           ...   \n",
       "6221     pseudoSales         2.352668      2.343562      2.411237   \n",
       "6222     meanSaleByWeek      2.343562      2.343562      2.343562   \n",
       "         pseudoSales         2.352668      2.343562      2.411237   \n",
       "6223     meanSaleByWeek      2.343562      2.343562      2.343562   \n",
       "         pseudoSales         2.352668      2.343562      2.411237   \n",
       "\n",
       "                         111 week ago  ...  9 week ago  8 week ago  \\\n",
       "articles typeData                      ...                           \n",
       "1        meanSaleByWeek      1.163938  ...    1.007993    1.007830   \n",
       "         pseudoSales         1.000000  ...    0.000001    0.000001   \n",
       "2        meanSaleByWeek      1.019503  ...    1.142640    1.018813   \n",
       "         pseudoSales         1.101542  ...    0.000001    0.000001   \n",
       "3        meanSaleByWeek      1.357727  ...    1.436232    1.230517   \n",
       "...                               ...  ...         ...         ...   \n",
       "6221     pseudoSales         2.434000  ...    0.000001    0.000001   \n",
       "6222     meanSaleByWeek      2.343562  ...    2.343562    2.343562   \n",
       "         pseudoSales         2.434000  ...    0.000001    0.000001   \n",
       "6223     meanSaleByWeek      2.343562  ...    2.343562    2.343562   \n",
       "         pseudoSales         2.434000  ...    0.000001    0.000001   \n",
       "\n",
       "                         7 week ago  6 week ago  5 week ago  4 week ago  \\\n",
       "articles typeData                                                         \n",
       "1        meanSaleByWeek    1.163938    1.007505    1.007343    1.007180   \n",
       "         pseudoSales       0.000001    0.000001    0.000001    0.000001   \n",
       "2        meanSaleByWeek    1.019503    1.020193    1.020882    1.272323   \n",
       "         pseudoSales       0.000001    0.000001    0.000001    0.000001   \n",
       "3        meanSaleByWeek    1.357727    1.487932    1.428296    1.602883   \n",
       "...                             ...         ...         ...         ...   \n",
       "6221     pseudoSales       0.000001    0.000001    0.000001    0.000001   \n",
       "6222     meanSaleByWeek    2.343562    2.343562    2.343562    2.343562   \n",
       "         pseudoSales       0.000001    0.000001    0.000001    0.000001   \n",
       "6223     meanSaleByWeek    2.343562    2.343562    2.343562    2.343562   \n",
       "         pseudoSales       0.000001    0.000001    0.000001    0.000001   \n",
       "\n",
       "                         3 week ago  2 week ago  1 week ago  split  \n",
       "articles typeData                                                   \n",
       "1        meanSaleByWeek    1.007018    1.006855    1.006692   test  \n",
       "         pseudoSales       0.000001    0.000001    0.000001   test  \n",
       "2        meanSaleByWeek    1.022258    1.022946    1.374266   test  \n",
       "         pseudoSales       0.000001    0.000001    0.000001   test  \n",
       "3        meanSaleByWeek    1.331203    1.329948    1.220094   test  \n",
       "...                             ...         ...         ...    ...  \n",
       "6221     pseudoSales       0.000001    0.000001    0.000001   test  \n",
       "6222     meanSaleByWeek    2.343562    2.343562    2.343562   test  \n",
       "         pseudoSales       0.000001    0.000001    0.000001   test  \n",
       "6223     meanSaleByWeek    2.343562    2.343562    2.343562   test  \n",
       "         pseudoSales       0.000001    0.000001    0.000001   test  \n",
       "\n",
       "[12446 rows x 121 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>120 week ago</th>\n",
       "      <th>119 week ago</th>\n",
       "      <th>118 week ago</th>\n",
       "      <th>117 week ago</th>\n",
       "      <th>116 week ago</th>\n",
       "      <th>115 week ago</th>\n",
       "      <th>114 week ago</th>\n",
       "      <th>113 week ago</th>\n",
       "      <th>112 week ago</th>\n",
       "      <th>111 week ago</th>\n",
       "      <th>...</th>\n",
       "      <th>9 week ago</th>\n",
       "      <th>8 week ago</th>\n",
       "      <th>7 week ago</th>\n",
       "      <th>6 week ago</th>\n",
       "      <th>5 week ago</th>\n",
       "      <th>4 week ago</th>\n",
       "      <th>3 week ago</th>\n",
       "      <th>2 week ago</th>\n",
       "      <th>1 week ago</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>articles</th>\n",
       "      <th>typeData</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>realSales</th>\n",
       "      <td>1.162653</td>\n",
       "      <td>1.111320</td>\n",
       "      <td>1.215417</td>\n",
       "      <td>1.115671</td>\n",
       "      <td>1.115671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>realSales</th>\n",
       "      <td>1.148691</td>\n",
       "      <td>1.193528</td>\n",
       "      <td>1.193528</td>\n",
       "      <td>1.101335</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>1.101542</td>\n",
       "      <td>...</td>\n",
       "      <td>1.085774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>realSales</th>\n",
       "      <td>1.275862</td>\n",
       "      <td>1.192088</td>\n",
       "      <td>1.275152</td>\n",
       "      <td>1.424745</td>\n",
       "      <td>1.492586</td>\n",
       "      <td>1.353890</td>\n",
       "      <td>1.101963</td>\n",
       "      <td>1.103052</td>\n",
       "      <td>1.103052</td>\n",
       "      <td>1.196674</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>realSales</th>\n",
       "      <td>1.137846</td>\n",
       "      <td>1.093975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.093552</td>\n",
       "      <td>1.093552</td>\n",
       "      <td>1.093552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.135495</td>\n",
       "      <td>1.264432</td>\n",
       "      <td>1.264432</td>\n",
       "      <td>1.146338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>realSales</th>\n",
       "      <td>1.307902</td>\n",
       "      <td>1.306110</td>\n",
       "      <td>1.211480</td>\n",
       "      <td>1.210080</td>\n",
       "      <td>1.383333</td>\n",
       "      <td>1.467296</td>\n",
       "      <td>1.391805</td>\n",
       "      <td>1.336528</td>\n",
       "      <td>1.240253</td>\n",
       "      <td>1.240253</td>\n",
       "      <td>...</td>\n",
       "      <td>1.093904</td>\n",
       "      <td>1.093904</td>\n",
       "      <td>1.093904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.098540</td>\n",
       "      <td>1.098540</td>\n",
       "      <td>1.188401</td>\n",
       "      <td>1.144653</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <th>realSales</th>\n",
       "      <td>2.575680</td>\n",
       "      <td>2.504132</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.440700</td>\n",
       "      <td>2.544569</td>\n",
       "      <td>...</td>\n",
       "      <td>2.730514</td>\n",
       "      <td>2.904503</td>\n",
       "      <td>2.863093</td>\n",
       "      <td>2.933092</td>\n",
       "      <td>2.829429</td>\n",
       "      <td>2.870143</td>\n",
       "      <td>2.876531</td>\n",
       "      <td>2.953212</td>\n",
       "      <td>3.037318</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <th>realSales</th>\n",
       "      <td>2.575680</td>\n",
       "      <td>2.504132</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.440700</td>\n",
       "      <td>2.544569</td>\n",
       "      <td>...</td>\n",
       "      <td>2.730514</td>\n",
       "      <td>2.904503</td>\n",
       "      <td>2.863093</td>\n",
       "      <td>2.933092</td>\n",
       "      <td>2.829429</td>\n",
       "      <td>2.870143</td>\n",
       "      <td>2.876531</td>\n",
       "      <td>2.953212</td>\n",
       "      <td>3.037318</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <th>realSales</th>\n",
       "      <td>2.575680</td>\n",
       "      <td>2.504132</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.440700</td>\n",
       "      <td>2.544569</td>\n",
       "      <td>...</td>\n",
       "      <td>2.730514</td>\n",
       "      <td>2.904503</td>\n",
       "      <td>2.863093</td>\n",
       "      <td>2.933092</td>\n",
       "      <td>2.829429</td>\n",
       "      <td>2.870143</td>\n",
       "      <td>2.876531</td>\n",
       "      <td>2.953212</td>\n",
       "      <td>3.037318</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <th>realSales</th>\n",
       "      <td>2.575680</td>\n",
       "      <td>2.504132</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.440700</td>\n",
       "      <td>2.544569</td>\n",
       "      <td>...</td>\n",
       "      <td>2.730514</td>\n",
       "      <td>2.904503</td>\n",
       "      <td>2.863093</td>\n",
       "      <td>2.933092</td>\n",
       "      <td>2.829429</td>\n",
       "      <td>2.870143</td>\n",
       "      <td>2.876531</td>\n",
       "      <td>2.953212</td>\n",
       "      <td>3.037318</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <th>realSales</th>\n",
       "      <td>2.575680</td>\n",
       "      <td>2.504132</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.383881</td>\n",
       "      <td>2.343562</td>\n",
       "      <td>2.440700</td>\n",
       "      <td>2.544569</td>\n",
       "      <td>...</td>\n",
       "      <td>2.730514</td>\n",
       "      <td>2.904503</td>\n",
       "      <td>2.863093</td>\n",
       "      <td>2.933092</td>\n",
       "      <td>2.829429</td>\n",
       "      <td>2.870143</td>\n",
       "      <td>2.876531</td>\n",
       "      <td>2.953212</td>\n",
       "      <td>3.037318</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6223 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    120 week ago  119 week ago  118 week ago  117 week ago  \\\n",
       "articles typeData                                                            \n",
       "1        realSales      1.162653      1.111320      1.215417      1.115671   \n",
       "2        realSales      1.148691      1.193528      1.193528      1.101335   \n",
       "3        realSales      1.275862      1.192088      1.275152      1.424745   \n",
       "4        realSales      1.137846      1.093975      1.000000      1.000000   \n",
       "5        realSales      1.307902      1.306110      1.211480      1.210080   \n",
       "...                          ...           ...           ...           ...   \n",
       "6219     realSales      2.575680      2.504132      2.343562      2.343562   \n",
       "6220     realSales      2.575680      2.504132      2.343562      2.343562   \n",
       "6221     realSales      2.575680      2.504132      2.343562      2.343562   \n",
       "6222     realSales      2.575680      2.504132      2.343562      2.343562   \n",
       "6223     realSales      2.575680      2.504132      2.343562      2.343562   \n",
       "\n",
       "                    116 week ago  115 week ago  114 week ago  113 week ago  \\\n",
       "articles typeData                                                            \n",
       "1        realSales      1.115671      1.000000      1.000000      1.000000   \n",
       "2        realSales      1.101542      1.101542      1.101542      1.101542   \n",
       "3        realSales      1.492586      1.353890      1.101963      1.103052   \n",
       "4        realSales      1.000000      1.093552      1.093552      1.093552   \n",
       "5        realSales      1.383333      1.467296      1.391805      1.336528   \n",
       "...                          ...           ...           ...           ...   \n",
       "6219     realSales      2.383881      2.383881      2.383881      2.343562   \n",
       "6220     realSales      2.383881      2.383881      2.383881      2.343562   \n",
       "6221     realSales      2.383881      2.383881      2.383881      2.343562   \n",
       "6222     realSales      2.383881      2.383881      2.383881      2.343562   \n",
       "6223     realSales      2.383881      2.383881      2.383881      2.343562   \n",
       "\n",
       "                    112 week ago  111 week ago  ...  9 week ago  8 week ago  \\\n",
       "articles typeData                               ...                           \n",
       "1        realSales      1.000000      1.000000  ...    1.000000    1.000000   \n",
       "2        realSales      1.101542      1.101542  ...    1.085774    1.000000   \n",
       "3        realSales      1.103052      1.196674  ...    1.000000    1.000000   \n",
       "4        realSales      1.000000      1.000000  ...    1.000000    1.135495   \n",
       "5        realSales      1.240253      1.240253  ...    1.093904    1.093904   \n",
       "...                          ...           ...  ...         ...         ...   \n",
       "6219     realSales      2.440700      2.544569  ...    2.730514    2.904503   \n",
       "6220     realSales      2.440700      2.544569  ...    2.730514    2.904503   \n",
       "6221     realSales      2.440700      2.544569  ...    2.730514    2.904503   \n",
       "6222     realSales      2.440700      2.544569  ...    2.730514    2.904503   \n",
       "6223     realSales      2.440700      2.544569  ...    2.730514    2.904503   \n",
       "\n",
       "                    7 week ago  6 week ago  5 week ago  4 week ago  \\\n",
       "articles typeData                                                    \n",
       "1        realSales    1.000000    1.000000    1.000000    1.000000   \n",
       "2        realSales    1.000000    1.000000    1.000000    1.000000   \n",
       "3        realSales    1.000000    1.000000    1.000000    1.000000   \n",
       "4        realSales    1.264432    1.264432    1.146338    1.000000   \n",
       "5        realSales    1.093904    1.000000    1.000000    1.098540   \n",
       "...                        ...         ...         ...         ...   \n",
       "6219     realSales    2.863093    2.933092    2.829429    2.870143   \n",
       "6220     realSales    2.863093    2.933092    2.829429    2.870143   \n",
       "6221     realSales    2.863093    2.933092    2.829429    2.870143   \n",
       "6222     realSales    2.863093    2.933092    2.829429    2.870143   \n",
       "6223     realSales    2.863093    2.933092    2.829429    2.870143   \n",
       "\n",
       "                    3 week ago  2 week ago  1 week ago  split  \n",
       "articles typeData                                              \n",
       "1        realSales    1.000000    1.000000    1.000000   test  \n",
       "2        realSales    1.000000    1.000000    1.000000   test  \n",
       "3        realSales    1.000000    1.000000    1.000000   test  \n",
       "4        realSales    1.000000    1.000000    1.000000   test  \n",
       "5        realSales    1.098540    1.188401    1.144653   test  \n",
       "...                        ...         ...         ...    ...  \n",
       "6219     realSales    2.876531    2.953212    3.037318   test  \n",
       "6220     realSales    2.876531    2.953212    3.037318   test  \n",
       "6221     realSales    2.876531    2.953212    3.037318   test  \n",
       "6222     realSales    2.876531    2.953212    3.037318   test  \n",
       "6223     realSales    2.876531    2.953212    3.037318   test  \n",
       "\n",
       "[6223 rows x 121 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = itemsDataset.load_dataset(args.pathToFile_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(args.mean, args.sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "def generate_batches(dataset, batch_size, shuffle= True, drop_last= True, device= 'cpu'):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset= dataset, batch_size= batch_size, shuffle= shuffle, drop_last= drop_last)\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for item, tensor in data_dict.items():\n",
    "            out_data_dict[item] = data_dict[item].to(args.device)\n",
    "        yield out_data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvRecNeuronNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvRecNeuronNet, self).__init__()\n",
    "        self.conv1= nn.Conv1d(in_channels= 2, out_channels= 32, kernel_size= 3, stride= 3)\n",
    "        self.conv1_bn= nn.BatchNorm1d(num_features= 32)\n",
    "        self.conv2= nn.Conv1d(in_channels= 32, out_channels= 48, kernel_size= 5, stride= 3, padding= 2)\n",
    "        self.conv2_bn= nn.BatchNorm1d(num_features= 48)\n",
    "        #self.birnn= nn.GRU(input_size= 30, hidden_size= args.rnn_hidden_size, num_layers= args.num_layers, \\\n",
    "                           #bidirectional=True, batch_first= True)\n",
    "        self.birnn= nn.LSTM(input_size=48, hidden_size= args.rnn_hidden_size, num_layers= args.num_layers, \\\n",
    "                               bidirectional=True, batch_first=True, dropout = 0.9)\n",
    "        self.initial_hidden = torch.zeros(2 * args.num_layers, args.batch_size, args.rnn_hidden_size).to(args.device)\n",
    "        self.initial_cell = torch.zeros(2 * args.num_layers, args.batch_size, args.rnn_hidden_size).to(args.device)\n",
    "        self.fc1= nn.Linear(2 * 14 * args.rnn_hidden_size, 120)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x= F.leaky_relu(self.conv1(x))\n",
    "        x= self.conv1_bn(x)\n",
    "        x= F.leaky_relu(self.conv2(x))\n",
    "        x= self.conv2_bn(x)\n",
    "        x= x.permute(0, 2, 1)\n",
    "        x_birnn_out, (x_birnn_h, x_birnn_c) = self.birnn(x, (self.initial_hidden, self.initial_cell))\n",
    "        batch_size, seq_size, feat_size = x_birnn_out.shape\n",
    "        x_birnn= x_birnn_out.contiguous().view(args.batch_size, seq_size * feat_size).unsqueeze(1)\n",
    "        x= F.leaky_relu(self.fc1(x_birnn))\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myFuncLossGet(x_vec):\n",
    "    c = [0.9, 1, 1, 1] # coef\n",
    "    b = [0.34, 0.24, 0, 0] # bias\n",
    "    d = [2, 2, 1, 2] # degree\n",
    "    coef = np.zeros_like(x_vec)\n",
    "    bias = np.zeros_like(x_vec)\n",
    "    degree = np.zeros_like(x_vec)\n",
    "    for i in range(x_vec.shape[0]):\n",
    "        for j in range(x_vec.shape[1]):\n",
    "            x = x_vec[i, j]\n",
    "            (coef[i, j], bias[i,j], degree[i, j]) = np.where(x < -1, (c[0], b[0], d[0]), np.where(x < -0.4, \\\n",
    "                                (c[1], b[1], d[1]), np.where(x < 0, (c[2], b[2], d[2]), (c[3], b[3], d[3]))))\n",
    "    return (coef, bias, degree)\n",
    "\n",
    "def PWLLoss(outputs, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "        Кусочно-линейная функция потерь. Штрафуется сильнее значение больше метки\n",
    "    \"\"\"\n",
    "    outputs = outputs.squeeze(1)\n",
    "    labels = labels.squeeze(1)\n",
    "    δ = torch.zeros(outputs.shape, requires_grad=True)\n",
    "    σ = torch.zeros(outputs.shape[0], requires_grad=True)\n",
    "    δ = labels - outputs\n",
    "    c, b, d = myFuncLossGet(δ.to('cpu').detach().numpy())\n",
    "    c = torch.from_numpy(c).to(args.device)\n",
    "    b = torch.from_numpy(b).to(args.device)\n",
    "    d = torch.from_numpy(d).to(args.device)\n",
    "    σ = torch.sum(c * torch.pow(torch.abs(δ), d) + b, dim=1)\n",
    "    return torch.mean(σ) \n",
    "\n",
    "def MyMSELoss(outputs, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "        Квадратичная функция потерь.\n",
    "    \"\"\"\n",
    "    outputs = outputs.squeeze(1)\n",
    "    labels = labels.squeeze(1)\n",
    "    δ = torch.zeros(outputs.shape, requires_grad=True)\n",
    "    σ = torch.zeros(outputs.shape[0], requires_grad=True)\n",
    "    δ = labels - outputs\n",
    "    σ = torch.sum(torch.pow(torch.abs(δ), 2), dim=1)\n",
    "    return torch.mean(σ) \n",
    "\n",
    "def MyMSELossWithPenaltyForSumDiff(outputs, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "        Квадратичная функция потерь с дополнительным штрафом за суммарную разность.\n",
    "    \"\"\"\n",
    "    \n",
    "    def myFuncSumDiffLoss(x):\n",
    "        vec_err = torch.zeros_like(x, requires_grad=True, device = args.device)      \n",
    "        vec_err = torch.abs(torch.pow((torch.exp(x) - torch.exp(-x)) / (torch.exp(x) + torch.exp(-x)), 1))\n",
    "        return vec_err\n",
    "    outputs = outputs.squeeze(1)\n",
    "    labels = labels.squeeze(1)\n",
    "    δ = torch.zeros(outputs[:, -16].shape, requires_grad=True, device = args.device)\n",
    "    δ_forecast = torch.zeros(outputs[:, -16:].shape, requires_grad=True, device = args.device)\n",
    "    cumsum_δ = torch.zeros((outputs.shape[0], 16), requires_grad=True, device = args.device) \n",
    "    σ = torch.zeros(outputs.shape[0], requires_grad=True, device = args.device)\n",
    "    δ = torch.abs(labels[:, 0:-16] - outputs[:, 0:-16])\n",
    "    δ_forecast = torch.abs(labels[:, -16:] - outputs[:, -16:])\n",
    "    cumsum_δ = torch.abs(torch.cumsum(labels[:, -16:], dim=1) - torch.cumsum(outputs[:, -16:], dim=1))\n",
    "    α, β, γ = 1, 3., 0.3\n",
    "    σ = α * torch.sum(torch.pow(δ, 2), dim=1) + β * torch.sum(torch.pow(δ_forecast, 2), dim=1) + \\\n",
    "        γ * torch.abs(torch.sum(myFuncSumDiffLoss(cumsum_δ), dim=1))\n",
    "    return torch.mean(σ)\n",
    "\n",
    "def SumDiffLoss(outputs, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "        Функция потерь с штрафом за суммарную разность.\n",
    "    \"\"\"\n",
    "    outputs = outputs.squeeze(1)\n",
    "    labels = labels.squeeze(1)\n",
    "    δ = torch.zeros(outputs[:, -16].shape, requires_grad=True, device = args.device)\n",
    "    δ_forecast = torch.zeros(outputs[:, -16:].shape, requires_grad=True, device = args.device)\n",
    "    cumsum_δ = torch.zeros((outputs.shape[0], 16), requires_grad=True, device = args.device)\n",
    "    σ = torch.zeros(outputs.shape[0], requires_grad=True, device = args.device)\n",
    "    δ = torch.abs(labels[:, 0:-16] - outputs[:, 0:-16])\n",
    "    δ_forecast = torch.abs(labels[:, -16:] - outputs[:, -16:])\n",
    "    cumsum_δ = torch.abs(torch.cumsum(labels[:, -16:], dim=1) - torch.cumsum(outputs[:, -16:], dim=1))\n",
    "#     norm_cumsum = torch.arange(1, cumsum_δ.shape[1]+1, device = args.device)\n",
    "    norm_cumsum = torch.tensor([0.2, 0.4, 0.6, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], device = args.device)\n",
    "    for i in range(outputs.shape[0]):\n",
    "        cumsum_δ[i, :] = cumsum_δ[i, :] / norm_cumsum\n",
    "    α, β, γ, θ = 1., 3., 1.5, 0.7 \n",
    "    σ = α * torch.sum(torch.pow(δ, 2), dim=1) + β * torch.sum(torch.pow(δ_forecast, 2), dim=1) + \\\n",
    "        γ * torch.sum(torch.pow(cumsum_δ, 2), dim=1) + θ * torch.sum(cumsum_δ, dim=1)\n",
    "#     σ = α * torch.sum(torch.pow(δ, 2), dim=1) + β * torch.sum(torch.abs(cumsum_δ), dim=1)\n",
    "    return torch.mean(σ)\n",
    "\n",
    "loss_fn = SumDiffLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvRecNeuronNet().to(args.device)\n",
    "# loss_fn = nn.MSELoss()\n",
    "# optimizer= optim.SGD(net.parameters(), lr= args.learning_rate)\n",
    "optimizer = optim.Adam(net.parameters(), lr= args.learning_rate, weight_decay=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \\\n",
    "u'C:\\\\Users\\\\MKoga\\\\MyProgramms\\\\BusinessAnalysis\\\\develop_forecast\\\\CNN_RNN_forecast_in_combination_with_recovery_new_last_ver3.pt'\n",
    "net.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "# writer.add_graph(net, torch.rand([args.batch_size, 1, args.rnn_hidden_size]).to(args.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_lr(model, loss_fn, optimizer, init_value=1e-5, final_value=1e-3):\n",
    "    batch_generator = generate_batches(dataset, batch_size = args.batch_size, device = args.device)\n",
    "    model.train()\n",
    "    numberOfBatchInEpoch = int(dataset.__len__() / args.batch_size)\n",
    "    print(numberOfBatchInEpoch, dataset.__len__())\n",
    "    update_step =  (final_value / init_value) ** ( 1 / (numberOfBatchInEpoch / 2))\n",
    "    print(update_step)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0][\"lr\"] = lr\n",
    "    best_loss = 0.0\n",
    "    best_lr = init_value\n",
    "    losses = []\n",
    "    running_loss= 0.0\n",
    "    log_lrs = []\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        \n",
    "        inputs, labels = batch_dict['x_data'].float(), batch_dict['y_target'].float() \n",
    "        # print(batch_dict['x_data'].shape)\n",
    "        optimizer.zero_grad() \n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        writer.add_scalar('loss', loss, batch_index)\n",
    "        \n",
    "        if batch_index > 1 and loss > 10000 * best_loss:\n",
    "            return log_lrs[10:-5], losses[10:-5], best_lr\n",
    "        if loss < best_loss or batch_index == 1:\n",
    "            best_loss = loss\n",
    "            best_lr = lr\n",
    "            \n",
    "        loss_batch = loss.to('cpu').item()\n",
    "        running_loss += (loss_batch - running_loss) / (batch_index + 1)\n",
    "        \n",
    "        losses.append(loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_index < (numberOfBatchInEpoch / 2):\n",
    "            lr *= update_step\n",
    "        else:\n",
    "            lr /= update_step\n",
    "        optimizer.param_groups[0][\"lr\"] = lr\n",
    "        \n",
    "        if batch_index % 20 == 19:\n",
    "            mean_value = np.mean(np.array(losses, dtype=np.float32))\n",
    "            print('[%5d]  (min loss %.4f, mean loss: %.4f,  best lr: %.8f)' %(batch_index + 1, best_loss, \n",
    "                mean_value, best_lr))\n",
    "            ax.clear()\n",
    "            ax.plot(log_lrs[10:-5], losses[10:-5])\n",
    "            ax.relim()\n",
    "            ax.autoscale_view(True, True, True)\n",
    "            fig.canvas.draw()\n",
    "            \n",
    "    return log_lrs[10:-5], losses[10:-5], best_lr, running_loss\n",
    "\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "\n",
    "for epoch_index in range(args.num_epochs):\n",
    "    \n",
    "    dataset.set_split('train')\n",
    "    logs, losses, best_lr, running_loss_train = find_lr(net, loss_fn, optimizer)\n",
    "    plt.plot(logs, losses)\n",
    "    loss_train.append(running_loss_train)\n",
    "    \n",
    "    dataset.set_split('val')\n",
    "    batch_generator = generate_batches(dataset, batch_size = args.batch_size, device = args.device)\n",
    "    net.eval()\n",
    "    running_loss_val = 0.0\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        y_pred = net(x = batch_dict['x_data'].to(dtype=torch.float32)).float().squeeze(1)\n",
    "        loss= loss_fn(y_pred, batch_dict['y_target'].float().squeeze(1))\n",
    "        loss_batch = loss.to('cpu').item()\n",
    "        running_loss_val += (loss_batch - running_loss_val) / (batch_index + 1)\n",
    "        if batch_index % 5 == 4:\n",
    "            print('[%5d] loss: %.3f' %(batch_index + 1, running_loss_val))\n",
    "    loss_val.append(running_loss_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train = np.array(loss_train)\n",
    "error_val = np.array(loss_val)\n",
    "epoch_index = np.arange(error_train.size)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.ylabel('Ошибка')\n",
    "plt.xlabel('Номер эпохи') \n",
    "plt.grid(True, axis='y', color='black',  linestyle='dashed')\n",
    "plt.grid(True, axis='x', color='black',  linestyle='dashed')\n",
    "plt.plot(epoch_index, error_train, label = 'train')\n",
    "plt.plot(epoch_index, error_val, label = 'validation')\n",
    "plt.legend()\n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \\\n",
    "u'C:\\\\Users\\\\MKoga\\\\MyProgramms\\\\BusinessAnalysis\\\\develop_forecast\\\\CNN_RNN_forecast_in_combination_with_recovery_new_ver5.pt'\n",
    "torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.xlim(-6.5, -3.5)\n",
    "plt.grid(True, axis='x', color='green',  linestyle='dashed')\n",
    "plt.plot(logs, losses)\n",
    "plt.vlines(-4.9, 0, 50, alpha=0.5, colors='r0', lw=5)\n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = u'C:\\\\Users\\\\MKoga\\\\MyProgramms\\\\BusinessAnalysis\\\\reconstactionData\\\\CNN_RNN_recovery_data_201120.pt'\n",
    "net.load_state_dict(torch.load(path))\n",
    "optimizer.param_groups[0][\"lr\"] = args.learning_rate\n",
    "loss_fn = MyMSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)\n",
    "# print(net.conv1.weight)\n",
    "# print(net.birnn.weight_hh_l1.data)\n",
    "print(f'shape of output layer {net.fc1.weight.data.shape}')\n",
    "print(np.argwhere(net.fc1.weight.data[0].to('cpu').abs() > 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch_index in range(args.num_epochs):\n",
    "    \n",
    "    dataset.set_split('train')\n",
    "    batch_generator = generate_batches(dataset, batch_size = args.batch_size, device = args.device)\n",
    "      \n",
    "    running_loss= 0.0\n",
    "    net.train()\n",
    "    \n",
    "    numberOfBatchInEpoch = int(dataset.__len__() / args.batch_size)\n",
    "    \n",
    "    for batch_index, batch_dict in enumerate(batch_generator):  \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #print(batch_dict['x_data'].float().shape)\n",
    "        y_pred = net(x = batch_dict['x_data'].float())\n",
    "        \n",
    "        \"\"\"\n",
    "        if batch_index == 100:\n",
    "            print(y_pred.shape, batch_dict['x_data'].float().squeeze(1)[:, :-1].shape, \\\n",
    "                  batch_dict['y_target'].float().squeeze(1).shape)\n",
    "            dif = y_pred.float() - batch_dict['y_target'].float().squeeze(1)\n",
    "            print(dif)\n",
    "            #print(y_pred, batch_dict['x_data'].float().squeeze(1)[:, :-1], batch_dict['y_target'].float().squeeze(1))\n",
    "        \"\"\"    \n",
    "        #print(y_pred.shape, batch_dict['y_target'].float().squeeze(1).shape)\n",
    "        loss = loss_fn(y_pred, batch_dict['y_target'].float()) #.squeeze(1))\n",
    "        writer.add_scalar('loss', loss, batch_index + epoch_index * numberOfBatchInEpoch)\n",
    "        print(loss)\n",
    "        loss_batch = loss.to('cpu').item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss_batch\n",
    "\n",
    "        if batch_index % 20 == 19:\n",
    "          print('[%d, %5d] loss: %.3f' %(epoch_index + 1, batch_index + 1, (running_loss / 20)))\n",
    "          running_loss= 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)\n",
    "# print(net.conv1.weight)\n",
    "print(net.birnn.weight_hh_l1.data)\n",
    "print(y_pred.squeeze(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(net.birnn.weight_hh_l1.data.abs() > 0.16).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvRecNeuronNet().to(args.device)\n",
    "path = u'C:\\\\Users\\\\MKoga\\\\MyProgramms\\\\BusinessAnalysis\\\\reconstactionData\\\\CNN_RNN_recovery_data_find_lr.pt'\n",
    "net.load_state_dict(torch.load(path))\n",
    "loss_fn = PWLLoss\n",
    "# net.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, batch_size = args.batch_size, device = args.device)\n",
    "running_loss= 0.0\n",
    "net.eval()\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    y_pred = net(x = batch_dict['x_data'].to(dtype=torch.float32)).float().squeeze(1)\n",
    "#     print('prediction shape - {}; target shape -{}'.format(y_pred.shape, batch_dict['y_target'].shape))\n",
    "    loss= loss_fn(y_pred, batch_dict['y_target'].float().squeeze(1))\n",
    "#     display(loss_fn(y_pred, batch_dict['y_target'].float()))\n",
    "    loss_batch = loss.to('cpu').item()\n",
    "    running_loss += loss_batch\n",
    "    if batch_index % 5 == 4:\n",
    "        print('[%5d] loss: %.3f' %(batch_index + 1, (running_loss / 5)))\n",
    "        running_loss= 0.0\n",
    "        data_in = np.array(batch_dict['x_data'].float()[:, 1, :].squeeze(1).to('cpu'))\n",
    "#         print('data_in.shape', data_in.shape)\n",
    "        dataY = np.array(batch_dict['y_target'].float().squeeze(1).to('cpu'))\n",
    "        y_pred = np.array(y_pred.to('cpu').squeeze(1).detach().numpy())\n",
    "#       здесь переход от нормального распределения к логнормальному \n",
    "        data_in[data_in != 1e-6] = args.normToLogNormData(data_in[data_in != 1e-6]) \n",
    "        data_in[data_in == 1e-6] = -1\n",
    "        dataY = args.normToLogNormData(dataY)\n",
    "        y_pred = args.normToLogNormData(y_pred)\n",
    "        y_pred[y_pred < 0.] = 0.\n",
    "#       -----------------------------------------------------------\n",
    "#       здесь восстановление ранее отнормированных данных -----------------------------------------------------\n",
    "#         data_in[data_in != -10] = rec_fromNorm(data_in[data_in != -10], args.mean, args.sd, args.f_recoveryData)\n",
    "#         data_in[data_in == -10] = -1\n",
    "#         dataY = rec_fromNorm(dataY, args.mean, args.sd, args.f_recoveryData)\n",
    "#         y_pred = rec_fromNorm(y_pred, args.mean, args.sd, args.f_recoveryData)\n",
    "#         y_pred[y_pred < 0.] = 0.\n",
    "#       -------------------------------------------------------------------------------------------------------\n",
    "        for i in range(3):\n",
    "            iData= np.random.randint(0, args.batch_size - 1)\n",
    "            pointForAverage = 1\n",
    "            step = int(pointForAverage / 2)\n",
    "            allWeek = int(data_in.shape[1] / pointForAverage)\n",
    "            allForecastWeek = int(y_pred.shape[1] / pointForAverage)\n",
    "            yPred= np.zeros(allForecastWeek, dtype= np.float32)\n",
    "            yReal= np.zeros(allForecastWeek, dtype= np.float32)\n",
    "            yInData= np.zeros(allWeek, dtype= np.float32)           \n",
    "            for j in range(allForecastWeek):\n",
    "                iterable_pred = (y_pred[iData, j*pointForAverage + k] for k in range(pointForAverage))  \n",
    "                yPred[j] = np.sum(np.fromiter(iterable_pred, dtype= np.float32))\n",
    "                iterable_real = (dataY[iData, j*pointForAverage + k] for k in range(pointForAverage)) \n",
    "                yReal[j] = np.sum(np.fromiter(iterable_real, dtype= np.float32))\n",
    "            for j in range(allWeek):\n",
    "                iterable_yInData = (data_in[iData, j*pointForAverage + k] for k in range(pointForAverage))\n",
    "                saleInIterableBool = [False if data_in[iData, j*pointForAverage + k] < 0 else True \\\n",
    "                              for k in range(pointForAverage)]\n",
    "                yInData[j] = np.sum(np.fromiter(iterable_yInData, dtype= np.float32), where= saleInIterableBool)\n",
    "                if not np.array(saleInIterableBool).any():\n",
    "                    yInData[j] = -1\n",
    "            week_forecast= np.arange(1 + step, allForecastWeek * pointForAverage + 1, pointForAverage)\n",
    "            week = np.arange(allForecastWeek*pointForAverage+1+step, (allWeek+allForecastWeek)*pointForAverage+1, \\\n",
    "                    pointForAverage)\n",
    "                                 \n",
    "            plt.rc('font', family='Verdana')\n",
    "            plt.rcParams.update({'font.size': 10, 'figure.figsize' : (8, 6), 'figure.dpi' : 200})  \n",
    "            plt.ioff()\n",
    "            fig= plt.figure()\n",
    "            ax= fig.add_subplot(111)\n",
    "            lab1= u'real sale'\n",
    "            ax.scatter(week_forecast, yReal, color= 'darkblue')\n",
    "            lab2= u'Predict sale'\n",
    "            ax.scatter(week_forecast, yPred, color='red', alpha=0.7)\n",
    "            lab3= u'change in-sale'\n",
    "            ax.scatter(week_forecast, yInData, color= 'green')\n",
    "            ax.legend((lab1, lab2, lab3), frameon=True, loc='best')\n",
    "            ax.set_ylabel('Предсказание')\n",
    "            ax.set_xlabel('Номер недели') \n",
    "            ax.grid(True, axis='y', color='black',  linestyle='dashed')\n",
    "            ax.grid(True, axis='x', color='black',  linestyle='dashed')\n",
    "            ax.set_xlim(0, allForecastWeek * pointForAverage + 1)\n",
    "#             ax.set_xlim((allWeek + allForecastWeek) * pointForAverage + 1, 0)\n",
    "            ax.set_ylim(-2, np.max([np.max(yInData), np.max(yPred), np.max(yReal)]))\n",
    "            plt.tight_layout() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_model_makeup(forecasts, facts):\n",
    "    γ = 0.2\n",
    "    err_exp_smooth = np.zeros((forecasts.shape[0], forecasts.shape[1], forecasts.shape[2]), dtype = 'f4')\n",
    "    ω = np.zeros((forecasts.shape[2], forecasts.shape[1]), dtype = 'f4')\n",
    "    def exponential_smoothing(series, alpha):\n",
    "        result = [np.abs(series[0])] # first value is same as series\n",
    "        for n in range(1, len(series)):\n",
    "            result.append(alpha * np.abs(series[n]) + (1 - alpha) * result[n-1])\n",
    "        return np.array(result)\n",
    "    facts = facts[:, :, np.newaxis]\n",
    "    err = np.abs(np.cumsum(forecasts - facts, axis=1))\n",
    "    for i in range(forecasts.shape[0]):\n",
    "        for n_model in range(forecasts.shape[2]):\n",
    "            err_exp_smooth[i, :, n_model] = exponential_smoothing(err[i, :, n_model], γ)\n",
    "    err_exp_smooth = err_exp_smooth.mean(axis = 0)\n",
    "    inverse_ω = np.power(err_exp_smooth, -1)\n",
    "    for j in range(forecasts.shape[2]):\n",
    "        ω[j] = inverse_ω[:, j] / np.sum(inverse_ω, axis = 1).reshape(-1)\n",
    "    return ω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.35715485 0.35256955 0.34764364 0.34450498 0.33956847 0.33601663\n",
      "  0.33405194 0.33273926 0.3313817  0.3301914  0.32932702 0.32833198\n",
      "  0.3274435  0.32670957 0.32619372 0.32556325]\n",
      " [0.25387985 0.25848386 0.26633236 0.27276537 0.28072008 0.2868467\n",
      "  0.29072097 0.2932305  0.2954047  0.29758623 0.29968148 0.30191937\n",
      "  0.30347976 0.30445346 0.30521485 0.3060613 ]\n",
      " [0.38896537 0.38894662 0.386024   0.38272965 0.37971148 0.37713668\n",
      "  0.37522712 0.37403026 0.37321362 0.37222233 0.3709915  0.36974868\n",
      "  0.36907676 0.368837   0.3685914  0.36837545]]\n",
      "{'models': {'C:\\\\Users\\\\MKoga\\\\MyProgramms\\\\BusinessAnalysis\\\\develop_forecast\\\\CNN_RNN_forecast_in_combination_with_recovery_new_last_ver1.pt': [0.35715484619140625, 0.3525695502758026, 0.34764364361763, 0.3445049822330475, 0.33956846594810486, 0.33601662516593933, 0.3340519368648529, 0.3327392637729645, 0.3313817083835602, 0.33019140362739563, 0.3293270170688629, 0.32833197712898254, 0.32744351029396057, 0.3267095685005188, 0.3261937201023102, 0.3255632519721985], 'C:\\\\Users\\\\MKoga\\\\MyProgramms\\\\BusinessAnalysis\\\\develop_forecast\\\\CNN_RNN_forecast_in_combination_with_recovery_new_last_ver3.pt': [0.2538798451423645, 0.2584838569164276, 0.26633235812187195, 0.2727653682231903, 0.2807200849056244, 0.28684669733047485, 0.29072096943855286, 0.29323050379753113, 0.29540470242500305, 0.29758623242378235, 0.29968148469924927, 0.3019193708896637, 0.30347976088523865, 0.30445346236228943, 0.30521485209465027, 0.3060612976551056], 'C:\\\\Users\\\\MKoga\\\\MyProgramms\\\\BusinessAnalysis\\\\develop_forecast\\\\CNN_RNN_forecast_in_combination_with_recovery_new_last_ver5.pt': [0.388965368270874, 0.38894662261009216, 0.38602399826049805, 0.3827296495437622, 0.37971147894859314, 0.3771366775035858, 0.3752271234989166, 0.3740302622318268, 0.37321361899375916, 0.37222233414649963, 0.3709914982318878, 0.36974868178367615, 0.36907675862312317, 0.36883699893951416, 0.36859139800071716, 0.3683754503726959]}}\n"
     ]
    }
   ],
   "source": [
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, batch_size = args.batch_size, device = args.device)\n",
    "net.eval()\n",
    "path_ver3 = u\"\"\"C:\\\\Users\\\\MKoga\\\\MyProgramms\\\\BusinessAnalysis\\\\develop_forecast\\\\\\\n",
    "CNN_RNN_forecast_in_combination_with_recovery_new_last_ver3.pt\"\"\"\n",
    "path_ver1 = u\"\"\"C:\\\\Users\\\\MKoga\\\\MyProgramms\\\\BusinessAnalysis\\\\develop_forecast\\\\\\\n",
    "CNN_RNN_forecast_in_combination_with_recovery_new_last_ver1.pt\"\"\"\n",
    "path_ver5 = u\"\"\"C:\\\\Users\\\\MKoga\\\\MyProgramms\\\\BusinessAnalysis\\\\develop_forecast\\\\\\\n",
    "CNN_RNN_forecast_in_combination_with_recovery_new_last_ver5.pt\"\"\"\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    \n",
    "#     exp_smooth_forecast_sales = np.zeros((args.batch_size, 16), dtype = np.float32)\n",
    "    net.load_state_dict(torch.load(path_ver3))\n",
    "    y_pred_ver3 = net(x = batch_dict['x_data'].to(dtype=torch.float32)).float().squeeze(1)\n",
    "    y_pred_ver3 = np.array(y_pred_ver3.to('cpu').squeeze(1).detach().numpy())[:, -16:]\n",
    "    \n",
    "    net.load_state_dict(torch.load(path_ver1))\n",
    "    y_pred_ver1 = net(x = batch_dict['x_data'].to(dtype=torch.float32)).float().squeeze(1)\n",
    "    y_pred_ver1 = np.array(y_pred_ver1.to('cpu').squeeze(1).detach().numpy())[:, -16:]\n",
    "    \n",
    "    net.load_state_dict(torch.load(path_ver5))\n",
    "    y_pred_ver5 = net(x = batch_dict['x_data'].to(dtype=torch.float32)).float().squeeze(1)\n",
    "    y_pred_ver5 = np.array(y_pred_ver5.to('cpu').squeeze(1).detach().numpy())[:, -16:]\n",
    "    \n",
    "#     # оценка временного ряда - экспоненциальное сглаживание\n",
    "#     def exponential_smoothing(series, alpha):\n",
    "#         result = [series[0]] # first value is same as series\n",
    "#         for n in range(1, len(series)):\n",
    "#             result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
    "#         return result[-1]\n",
    "#     cur_series = batch_dict['x_data'].float()[:, 0, :]\n",
    "#     cur_series = cur_series.to('cpu').squeeze(1).detach().numpy()\n",
    "#     alpha = 0.019\n",
    "#     for item in range(cur_series.shape[0]):\n",
    "#         exp_smoth_forecast_sale = np.array([exponential_smoothing(cur_series[item, :], alpha)])\n",
    "#         for _ in range(15):\n",
    "#             cur_series[item] = np.hstack([cur_series[item, 1:], exp_smoth_forecast_sale[-1]])\n",
    "#             exp_smoth_forecast_sale = \\\n",
    "#                 np.hstack([exp_smoth_forecast_sale, exponential_smoothing(cur_series[item, :], alpha)])\n",
    "#         exp_smooth_forecast_sales[item, :] = exp_smoth_forecast_sale\n",
    "#     # -------------------------------------------\n",
    "    \n",
    "    forecasts = np.dstack((y_pred_ver1, y_pred_ver3, y_pred_ver5)) #, exp_smooth_forecast_sales)) \n",
    "    facts = batch_dict['y_target'].float()[:, :, -16:]\n",
    "    facts = facts.to('cpu').squeeze(1).detach().numpy()\n",
    "#     print(forecasts.shape, facts.shape)\n",
    "    if batch_index == 0:\n",
    "        w = adaptive_model_makeup(forecasts, facts)\n",
    "    else:\n",
    "        w = np.dstack((w, adaptive_model_makeup(forecasts, facts)))\n",
    "\n",
    "makeup_weights = np.mean(w, axis=2)\n",
    "dic_makeup_weights = {'models' : {path_ver1 : [float(x) for x in makeup_weights[0, :]], \n",
    "                                  path_ver3 : [float(x) for x in makeup_weights[1, :]], \n",
    "                                  path_ver5 : [float(x) for x in makeup_weights[2, :]]}}\n",
    "print(makeup_weights)\n",
    "print(dic_makeup_weights)\n",
    "\n",
    "import json\n",
    "with open('makeup_ver1_ver3_ver5_models.json', 'w') as makeup_models:\n",
    "    json.dump(dic_makeup_weights, makeup_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "week_forecast = np.arange(16)\n",
    "err_y_pred_ver3 = np.cumsum(y_pred_ver3 - facts, axis=1).mean(axis=0)\n",
    "err_y_pred_ver1 = np.cumsum(y_pred_ver1 - facts, axis=1).mean(axis=0)\n",
    "err_y_pred_ver5 = np.cumsum(y_pred_ver5 - facts, axis=1).mean(axis=0)\n",
    "# err_esm = np.abs(np.cumsum(exp_smooth_forecast_sales - facts, axis=1)).mean(axis=0)\n",
    "# err_mwa = np.abs(np.cumsum(rolling_weights_mean_sale - facts, axis=1)).mean(axis=0)\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(111)\n",
    "lab1= u'cumsum neuron Predict sale ver3'\n",
    "ax1.scatter(week_forecast, err_y_pred_ver3, color= 'darkblue')\n",
    "lab2= u'cumsum neuron Predict sale ver1'\n",
    "ax1.scatter(week_forecast, err_y_pred_ver1, color='red', alpha=0.7)\n",
    "lab3= u'cumsum neuron Predict sale ver5'\n",
    "ax1.scatter(week_forecast, err_y_pred_ver5, color='orange', alpha=0.7)\n",
    "# lab4= u'cumsum exp smooth mean'\n",
    "# ax1.scatter(week_forecast, err_esm, color='green', alpha=0.7)\n",
    "ax1.set_ylabel('Предсказание')\n",
    "ax1.set_xlabel('Номер недели') \n",
    "ax1.grid(True, axis='y', color='black',  linestyle='dashed')\n",
    "ax1.grid(True, axis='x', color='black',  linestyle='dashed')\n",
    "ax1.set_xlim(0, 16)\n",
    "ax1.set_ylim(np.min([err_y_pred_ver3, err_y_pred_ver1, err_y_pred_ver5]) - 1, \\\n",
    "             np.max([err_y_pred_ver3, err_y_pred_ver1, err_y_pred_ver5]) + 1)\n",
    "ax1.legend((lab1, lab2, lab3), frameon=True, loc='best')\n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ab'])\n"
     ]
    }
   ],
   "source": [
    "a = {'ab': [1,2,3]}\n",
    "b = a.keys()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
